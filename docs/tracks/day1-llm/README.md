# Day 1 â€“ LLMs & Prompting - Workshop Materials

Welcome to Day 1 of the watsonx Workshop! This directory contains all materials for learning LLM fundamentals and prompt engineering.

---

## Quick Start

1. **Theory First** (Morning, 4 hours):
   - Read `llm-concepts.md`
   - Read `prompt-patterns-theory.md`
   - Read `eval-safety-theory.md`

2. **Labs Second** (Afternoon, 4 hours):
   - Follow `lab-1-quickstart-two-envs.md`
   - Follow `lab-2-prompt-templates.md`
   - Follow `lab-3-micro-eval.md`

3. **Reference**:
   - See `day1-summary-and-schedule.md` for complete overview

---

## File Structure

```
day1-llm/
â”œâ”€â”€ README.md (this file)
â”œâ”€â”€ day1-summary-and-schedule.md
â”‚
â”œâ”€â”€ Theory (Morning)
â”‚   â”œâ”€â”€ llm-concepts.md
â”‚   â”œâ”€â”€ prompt-patterns-theory.md
â”‚   â””â”€â”€ eval-safety-theory.md
â”‚
â”œâ”€â”€ Lab Instructions (Afternoon)
â”‚   â”œâ”€â”€ lab-1-quickstart-two-envs.md
â”‚   â”œâ”€â”€ lab-2-prompt-templates.md
â”‚   â””â”€â”€ lab-3-micro-eval.md
â”‚
â””â”€â”€ Notebooks (Created by you during labs)
    â”œâ”€â”€ ollama_quickstart.ipynb
    â”œâ”€â”€ watsonx_quickstart.ipynb
    â”œâ”€â”€ prompt_patterns_ollama.ipynb
    â”œâ”€â”€ prompt_patterns_watsonx.ipynb
    â””â”€â”€ micro_evaluation.ipynb
```

---

## Learning Objectives

### Theory Modules

**1.0 LLM Concepts** (`llm-concepts.md`)
- Understand tokens, context windows, and key parameters
- Compare local (Ollama) vs managed (watsonx.ai) deployments
- Learn cost and resource considerations
- See how LLMs fit in production architecture

**1.2 Prompt Patterns** (`prompt-patterns-theory.md`)
- Master common prompt patterns (instruction, few-shot, CoT, style transfer)
- Learn prompt design principles
- Create reusable templates
- Understand accelerator prompt structure

**1.3 Evaluation & Safety** (`eval-safety-theory.md`)
- Know why evaluation matters
- Understand evaluation signals (correctness, coherence, style, latency)
- Learn safety considerations
- Design production monitoring

### Lab Modules

**Lab 1.1: Quickstart** (`lab-1-quickstart-two-envs.md`)
- Duration: 45 minutes
- Run first prompts in Ollama and watsonx.ai
- Modify parameters (temperature, max_tokens)
- Compare outputs and latency

**Lab 1.2: Prompt Templates** (`lab-2-prompt-templates.md`)
- Duration: 60 minutes
- Build reusable templates for summarization, style transfer, Q&A
- Implement in both environments
- Run comparative experiments

**Lab 1.3: Micro-Evaluation** (`lab-3-micro-eval.md`)
- Duration: 60 minutes
- Create test set of prompts
- Apply rating rubric
- Analyze results with pandas and visualizations

---

## Prerequisites

Before Day 1:
- âœ… Complete Day 0 (environment setup)
- âœ… `simple-ollama-environment` working
- âœ… `simple-watsonx-enviroment` with valid credentials
- âœ… Jupyter accessible in both environments

---

## Workshop Flow

```
Morning (Theory)
â”œâ”€â”€ 9:00-10:30   â”‚ 1.0 LLM Concepts
â”œâ”€â”€ 10:30-10:45  â”‚ Break
â”œâ”€â”€ 10:45-11:45  â”‚ 1.2 Prompt Patterns
â”œâ”€â”€ 11:45-12:00  â”‚ Q&A
â””â”€â”€ 12:00-13:00  â”‚ Lunch

Afternoon (Labs)
â”œâ”€â”€ 13:00-13:45  â”‚ Lab 1.1: Quickstart
â”œâ”€â”€ 13:45-14:45  â”‚ Lab 1.2: Templates
â”œâ”€â”€ 14:45-15:00  â”‚ Break
â”œâ”€â”€ 15:00-16:00  â”‚ Lab 1.3: Evaluation
â”œâ”€â”€ 16:00-16:30  â”‚ 1.3 Evaluation Theory
â””â”€â”€ 16:30-17:00  â”‚ Wrap-up & Q&A
```

---

## Key Concepts

### Tokens
- Sub-units of text (~4 chars/token in English)
- Models have token limits (context windows)
- Costs calculated per token

### Temperature
- `0.0` = Deterministic, focused
- `0.7-1.0` = Balanced creativity
- `1.5+` = Very creative, less predictable

### Prompt Patterns
1. **Instruction**: Direct command
2. **Few-shot**: Examples before task
3. **Chain-of-thought**: Step-by-step reasoning
4. **Style transfer**: Rewrite in different tone
5. **Summarization**: Condense content

### Evaluation
- **Correctness**: Matches ground truth?
- **Coherence**: Logical and relevant?
- **Style**: Follows format?
- **Latency**: Fast enough?

---

## Deliverables

By end of Day 1, you will have:
- âœ… 5 working Jupyter notebooks
- âœ… Reusable prompt templates
- âœ… Evaluation results (CSV + visualizations)
- âœ… Understanding of LLM fundamentals

---

## Common Issues & Solutions

### Ollama
**Problem**: Connection refused  
**Solution**: Check if Ollama service is running
```bash
curl http://localhost:11434/api/tags
```

**Problem**: Model not found  
**Solution**: Pull the model
```bash
ollama pull qwen2.5:0.5b-instruct
```

### watsonx.ai
**Problem**: Invalid API key  
**Solution**: Check `.env` file, verify key in IBM Cloud console

**Problem**: Rate limit  
**Solution**: Add delays between requests (`time.sleep(0.5)`)

### General
**Problem**: Wrong Python kernel  
**Solution**: Select correct kernel in Jupyter (e.g., "Python 3.11 (simple-env)")

---

## Tips for Success

### Theory Sessions
- Take notes on key concepts
- Ask questions when unclear
- Relate concepts to your use cases

### Lab Sessions
- Follow instructions step-by-step
- Experiment beyond the examples
- Document interesting findings
- Help peers when possible

### Time Management
- Don't get stuck on one issue too long
- Ask for help after 5-10 minutes
- Labs build on each otherâ€”complete in order

---

## Resources

### Documentation
- [IBM Granite Models](https://www.ibm.com/granite/docs)
- [watsonx.ai Docs](https://www.ibm.com/docs/en/watsonx-as-a-service)
- [Ollama Documentation](https://ollama.com/docs)

### Prompt Engineering
- [OpenAI Prompt Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [Anthropic Prompt Tips](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [Granite Prompting](https://www.ibm.com/granite/docs/models/granite/#chat-template)

### Python & Data Science
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Jupyter Notebook Guide](https://jupyter-notebook.readthedocs.io/)

---

## Next Steps

### After Day 1
1. Review your notebooks and notes
2. Complete optional homework (expand test sets)
3. Read ahead: Day 2 materials on RAG

### Day 2 Preview
Tomorrow we'll learn:
- **Retrieval-Augmented Generation (RAG)**
- **Vector databases** (Elasticsearch, Chroma)
- **Embedding models**
- **Accelerator integration**

---

## Getting Help

### During Workshop
- ğŸ’¬ Chat/Slack for questions
- ğŸ™‹ Raise hand for blocking issues
- ğŸ‘¥ Discuss with neighbors

### After Workshop
- ğŸ“§ Email instructors
- ğŸ’» GitHub issues/discussions
- ğŸŒ Community forums

---

## Feedback

Your feedback helps improve the workshop!

**Please share**:
- What worked well?
- What was confusing?
- What would you like more/less of?
- Suggestions for improvement?

---

## License & Attribution

Materials created for the watsonx Workshop Series.

**Based on**:
- IBM Granite documentation
- watsonx.ai best practices
- Community contributions

---

## Version History

- **v1.0** (2025-01): Initial release
  - Theory modules
  - Lab instructions
  - Reference notebooks

---

**Ready to start? Begin with `llm-concepts.md`! ğŸš€**

For questions or issues, contact your workshop instructor.
