{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Watsonx.ai + LangGraph: Multi-Agent Systems Tutorial\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to this comprehensive tutorial on building **Multi-Agent Systems** using **IBM watsonx.ai** and **LangGraph**!\n",
    "\n",
    "### What You'll Learn:\n",
    "\n",
    "1. **LangGraph Fundamentals** - Understanding state graphs and workflows\n",
    "2. **Watsonx.ai Integration** - Connecting IBM's powerful LLMs\n",
    "3. **Single Agent Systems** - Building your first LangGraph agent\n",
    "4. **Multi-Agent Systems** - Creating collaborative AI agents\n",
    "5. **Real-World Applications** - Practical use cases\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "- IBM Cloud account with watsonx.ai access\n",
    "- API Key and Project ID from watsonx.ai\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Table of Contents\n",
    "\n",
    "1. [Setup & Installation](#setup)\n",
    "2. [LangGraph Basics](#basics)\n",
    "3. [Single Agent Example](#single)\n",
    "4. [Multi-Agent Systems](#multi)\n",
    "5. [Advanced Patterns](#advanced)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Installation <a id=\"setup\"></a>\n",
    "\n",
    "First, let's install all required packages for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q langgraph langchain langchain-ibm python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Your Credentials\n",
    "\n",
    "For Google Colab, we'll use manual input. In production, use environment variables or `.env` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Set your credentials here\n",
    "# Get your credentials from: https://cloud.ibm.com/iam/apikeys\n",
    "\n",
    "if \"WATSONX_API_KEY\" not in os.environ:\n",
    "    os.environ[\"WATSONX_API_KEY\"] = getpass.getpass(\"Enter your Watsonx API Key: \")\n",
    "\n",
    "if \"WATSONX_URL\" not in os.environ:\n",
    "    os.environ[\"WATSONX_URL\"] = input(\"Enter your Watsonx URL (default: https://us-south.ml.cloud.ibm.com): \") or \"https://us-south.ml.cloud.ibm.com\"\n",
    "\n",
    "if \"PROJECT_ID\" not in os.environ:\n",
    "    os.environ[\"PROJECT_ID\"] = getpass.getpass(\"Enter your Project ID: \")\n",
    "\n",
    "print(\"‚úÖ Credentials configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. LangGraph Basics <a id=\"basics\"></a>\n",
    "\n",
    "### What is LangGraph?\n",
    "\n",
    "**LangGraph** is a library for building stateful, multi-actor applications with LLMs. It extends LangChain with:\n",
    "\n",
    "- **State Management**: Maintain conversation context across nodes\n",
    "- **Graph-Based Workflows**: Define complex agent interactions\n",
    "- **Conditional Edges**: Dynamic routing based on state\n",
    "- **Multi-Agent Orchestration**: Coordinate multiple AI agents\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Nodes**: Functions that process the state\n",
    "2. **Edges**: Connections between nodes\n",
    "3. **State**: Shared data structure passed between nodes\n",
    "4. **Graph**: The workflow definition\n",
    "\n",
    "### Architecture Diagram:\n",
    "\n",
    "```\n",
    "START ‚Üí Node 1 ‚Üí Node 2 ‚Üí Node 3 ‚Üí END\n",
    "          ‚Üì        ‚Üì        ‚Üì\n",
    "        State    State    State\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Single Agent Example <a id=\"single\"></a>\n",
    "\n",
    "Let's start with a simple single-agent example using watsonx.ai and LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Initialize Watsonx LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import WatsonxLLM\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain.schema import HumanMessage, AIMessage, BaseMessage\n",
    "import operator\n",
    "\n",
    "# Load credentials\n",
    "api_key = os.getenv(\"WATSONX_API_KEY\")\n",
    "url = os.getenv(\"WATSONX_URL\")\n",
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "\n",
    "# Initialize Watsonx LLM\n",
    "model_id = \"ibm/granite-13b-instruct-v2\"\n",
    "\n",
    "watsonx_llm = WatsonxLLM(\n",
    "    model_id=model_id,\n",
    "    url=url,\n",
    "    apikey=api_key,\n",
    "    project_id=project_id,\n",
    "    params={\n",
    "        \"decoding_method\": \"greedy\",\n",
    "        \"max_new_tokens\": 300,\n",
    "        \"temperature\": 0.7\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Watsonx LLM initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Define State Structure\n",
    "\n",
    "The state holds the conversation history and any metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state structure\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    \n",
    "print(\"‚úÖ State structure defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Create Simple Agent Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_agent(state: AgentState) -> AgentState:\n",
    "    \"\"\"\n",
    "    A simple agent that processes messages and generates responses.\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # Get the last user message\n",
    "    last_message = messages[-1].content\n",
    "    \n",
    "    # Generate response using Watsonx\n",
    "    response = watsonx_llm.invoke(last_message)\n",
    "    \n",
    "    # Return updated state\n",
    "    return {\"messages\": [AIMessage(content=response)]}\n",
    "\n",
    "print(\"‚úÖ Simple agent node created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Build and Run the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Add the agent node\n",
    "workflow.add_node(\"agent\", simple_agent)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add edge to END\n",
    "workflow.add_edge(\"agent\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Graph compiled successfully!\")\n",
    "print(\"\\nüìä Graph structure:\")\n",
    "print(\"START ‚Üí agent ‚Üí END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test the Single Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Tell me a joke about AI.\")]}\n",
    "result = app.invoke(inputs)\n",
    "\n",
    "print(\"ü§ñ Agent Response:\")\n",
    "print(\"=\"*50)\n",
    "print(result[\"messages\"][-1].content)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Multi-Agent Systems <a id=\"multi\"></a>\n",
    "\n",
    "Now let's build a **multi-agent system** where different agents collaborate to solve complex tasks.\n",
    "\n",
    "### Use Case: Research Team\n",
    "\n",
    "We'll create three specialized agents:\n",
    "1. **Researcher**: Gathers information\n",
    "2. **Analyst**: Analyzes the information\n",
    "3. **Writer**: Produces the final output\n",
    "\n",
    "### Multi-Agent Architecture:\n",
    "\n",
    "```\n",
    "START ‚Üí Researcher ‚Üí Analyst ‚Üí Writer ‚Üí END\n",
    "          ‚Üì           ‚Üì         ‚Üì\n",
    "        State       State     State\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Define Enhanced State\n",
    "\n",
    "For multi-agent systems, we need a richer state structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "class MultiAgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    topic: str\n",
    "    research_findings: str\n",
    "    analysis: str\n",
    "    final_report: str\n",
    "    current_agent: str\n",
    "\n",
    "print(\"‚úÖ Multi-agent state structure defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create Specialized Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def researcher_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"\n",
    "    Researcher Agent: Gathers information about the topic.\n",
    "    \"\"\"\n",
    "    topic = state.get(\"topic\", \"AI\")\n",
    "    \n",
    "    prompt = f\"\"\"You are a research specialist. Provide 3-4 key facts about: {topic}\n",
    "    Focus on recent developments and important concepts.\n",
    "    Format your response as bullet points.\"\"\"\n",
    "    \n",
    "    research = watsonx_llm.invoke(prompt)\n",
    "    \n",
    "    print(\"\\nüîç Researcher Agent completed its task\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Research completed on: {topic}\")],\n",
    "        \"research_findings\": research,\n",
    "        \"current_agent\": \"researcher\"\n",
    "    }\n",
    "\n",
    "\n",
    "def analyst_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"\n",
    "    Analyst Agent: Analyzes the research findings.\n",
    "    \"\"\"\n",
    "    research = state.get(\"research_findings\", \"\")\n",
    "    topic = state.get(\"topic\", \"AI\")\n",
    "    \n",
    "    prompt = f\"\"\"You are a data analyst. Analyze these research findings about {topic}:\n",
    "    \n",
    "    {research}\n",
    "    \n",
    "    Provide:\n",
    "    1. Key insights\n",
    "    2. Trends or patterns\n",
    "    3. Implications\n",
    "    \n",
    "    Keep your analysis concise.\"\"\"\n",
    "    \n",
    "    analysis = watsonx_llm.invoke(prompt)\n",
    "    \n",
    "    print(\"\\nüìä Analyst Agent completed its task\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Analysis completed on research findings\")],\n",
    "        \"analysis\": analysis,\n",
    "        \"current_agent\": \"analyst\"\n",
    "    }\n",
    "\n",
    "\n",
    "def writer_agent(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"\n",
    "    Writer Agent: Creates the final report.\n",
    "    \"\"\"\n",
    "    research = state.get(\"research_findings\", \"\")\n",
    "    analysis = state.get(\"analysis\", \"\")\n",
    "    topic = state.get(\"topic\", \"AI\")\n",
    "    \n",
    "    prompt = f\"\"\"You are a technical writer. Create a concise report about {topic} using:\n",
    "    \n",
    "    Research Findings:\n",
    "    {research}\n",
    "    \n",
    "    Analysis:\n",
    "    {analysis}\n",
    "    \n",
    "    Write a clear, professional summary in 2-3 paragraphs.\"\"\"\n",
    "    \n",
    "    final_report = watsonx_llm.invoke(prompt)\n",
    "    \n",
    "    print(\"\\n‚úçÔ∏è  Writer Agent completed its task\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Final report completed\")],\n",
    "        \"final_report\": final_report,\n",
    "        \"current_agent\": \"writer\"\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ All specialized agents created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Build Multi-Agent Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the multi-agent graph\n",
    "multi_agent_workflow = StateGraph(MultiAgentState)\n",
    "\n",
    "# Add all agent nodes\n",
    "multi_agent_workflow.add_node(\"researcher\", researcher_agent)\n",
    "multi_agent_workflow.add_node(\"analyst\", analyst_agent)\n",
    "multi_agent_workflow.add_node(\"writer\", writer_agent)\n",
    "\n",
    "# Set entry point\n",
    "multi_agent_workflow.set_entry_point(\"researcher\")\n",
    "\n",
    "# Define the workflow edges\n",
    "multi_agent_workflow.add_edge(\"researcher\", \"analyst\")\n",
    "multi_agent_workflow.add_edge(\"analyst\", \"writer\")\n",
    "multi_agent_workflow.add_edge(\"writer\", END)\n",
    "\n",
    "# Compile the multi-agent graph\n",
    "multi_agent_app = multi_agent_workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Multi-agent workflow compiled successfully!\")\n",
    "print(\"\\nüìä Multi-Agent Graph Structure:\")\n",
    "print(\"START ‚Üí Researcher ‚Üí Analyst ‚Üí Writer ‚Üí END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Run Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the multi-agent system\n",
    "topic = \"Quantum Computing\"\n",
    "\n",
    "print(f\"\\nüöÄ Starting Multi-Agent Research on: {topic}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=f\"Research and analyze {topic}\")],\n",
    "    \"topic\": topic,\n",
    "    \"research_findings\": \"\",\n",
    "    \"analysis\": \"\",\n",
    "    \"final_report\": \"\",\n",
    "    \"current_agent\": \"start\"\n",
    "}\n",
    "\n",
    "result = multi_agent_app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Multi-Agent Process Complete!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã RESEARCH FINDINGS\")\n",
    "print(\"=\"*60)\n",
    "print(result.get(\"research_findings\", \"No findings\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(result.get(\"analysis\", \"No analysis\"))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìÑ FINAL REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(result.get(\"final_report\", \"No report\"))\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Advanced Patterns <a id=\"advanced\"></a>\n",
    "\n",
    "### 5.1 Conditional Routing\n",
    "\n",
    "Let's create a system where agents can make decisions about workflow routing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "class RoutingState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    question_type: str\n",
    "    response: str\n",
    "\n",
    "\n",
    "def classifier_agent(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"\n",
    "    Classifies the type of question.\n",
    "    \"\"\"\n",
    "    question = state[\"messages\"][-1].content\n",
    "    \n",
    "    prompt = f\"\"\"Classify this question into ONE category: 'technical', 'creative', or 'general'\n",
    "    Question: {question}\n",
    "    \n",
    "    Respond with ONLY the category word, nothing else.\"\"\"\n",
    "    \n",
    "    classification = watsonx_llm.invoke(prompt).strip().lower()\n",
    "    \n",
    "    # Ensure valid classification\n",
    "    if classification not in ['technical', 'creative', 'general']:\n",
    "        classification = 'general'\n",
    "    \n",
    "    print(f\"\\nüéØ Question classified as: {classification}\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Classified as {classification}\")],\n",
    "        \"question_type\": classification\n",
    "    }\n",
    "\n",
    "\n",
    "def technical_agent(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"\n",
    "    Handles technical questions.\n",
    "    \"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    prompt = f\"\"\"As a technical expert, answer this question with precision:\n",
    "    {question}\"\"\"\n",
    "    \n",
    "    response = watsonx_llm.invoke(prompt)\n",
    "    print(\"\\nüîß Technical Agent responded\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "\n",
    "def creative_agent(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"\n",
    "    Handles creative questions.\n",
    "    \"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    prompt = f\"\"\"As a creative writer, answer this question imaginatively:\n",
    "    {question}\"\"\"\n",
    "    \n",
    "    response = watsonx_llm.invoke(prompt)\n",
    "    print(\"\\nüé® Creative Agent responded\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "\n",
    "def general_agent(state: RoutingState) -> RoutingState:\n",
    "    \"\"\"\n",
    "    Handles general questions.\n",
    "    \"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    prompt = f\"\"\"Answer this general question clearly and concisely:\n",
    "    {question}\"\"\"\n",
    "    \n",
    "    response = watsonx_llm.invoke(prompt)\n",
    "    print(\"\\nüí¨ General Agent responded\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"response\": response\n",
    "    }\n",
    "\n",
    "\n",
    "def route_question(state: RoutingState) -> str:\n",
    "    \"\"\"\n",
    "    Routes to the appropriate agent based on classification.\n",
    "    \"\"\"\n",
    "    question_type = state.get(\"question_type\", \"general\")\n",
    "    \n",
    "    routing_map = {\n",
    "        \"technical\": \"technical_agent\",\n",
    "        \"creative\": \"creative_agent\",\n",
    "        \"general\": \"general_agent\"\n",
    "    }\n",
    "    \n",
    "    return routing_map.get(question_type, \"general_agent\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Conditional routing agents created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Build Routing Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create routing workflow\n",
    "routing_workflow = StateGraph(RoutingState)\n",
    "\n",
    "# Add nodes\n",
    "routing_workflow.add_node(\"classifier\", classifier_agent)\n",
    "routing_workflow.add_node(\"technical_agent\", technical_agent)\n",
    "routing_workflow.add_node(\"creative_agent\", creative_agent)\n",
    "routing_workflow.add_node(\"general_agent\", general_agent)\n",
    "\n",
    "# Set entry point\n",
    "routing_workflow.set_entry_point(\"classifier\")\n",
    "\n",
    "# Add conditional edges\n",
    "routing_workflow.add_conditional_edges(\n",
    "    \"classifier\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"technical_agent\": \"technical_agent\",\n",
    "        \"creative_agent\": \"creative_agent\",\n",
    "        \"general_agent\": \"general_agent\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add edges to END\n",
    "routing_workflow.add_edge(\"technical_agent\", END)\n",
    "routing_workflow.add_edge(\"creative_agent\", END)\n",
    "routing_workflow.add_edge(\"general_agent\", END)\n",
    "\n",
    "# Compile\n",
    "routing_app = routing_workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Routing workflow compiled!\")\n",
    "print(\"\\nüìä Routing Graph Structure:\")\n",
    "print(\"\"\"START ‚Üí Classifier ‚Üí [Technical Agent]\n",
    "                    ‚Üí [Creative Agent]\n",
    "                    ‚Üí [General Agent] ‚Üí END\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Test Conditional Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with different question types\n",
    "test_questions = [\n",
    "    \"Explain how neural networks work\",\n",
    "    \"Write a short poem about clouds\",\n",
    "    \"What is the capital of France?\"\n",
    "]\n",
    "\n",
    "for question in test_questions:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"‚ùì Question: {question}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    result = routing_app.invoke({\n",
    "        \"messages\": [HumanMessage(content=question)],\n",
    "        \"question_type\": \"\",\n",
    "        \"response\": \"\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüí° Response:\\n{result['response']}\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Real-World Use Cases\n",
    "\n",
    "### Customer Support System\n",
    "\n",
    "Let's build a practical customer support multi-agent system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    customer_query: str\n",
    "    issue_category: str\n",
    "    solution: str\n",
    "    escalation_needed: bool\n",
    "\n",
    "\n",
    "def triage_agent(state: SupportState) -> SupportState:\n",
    "    \"\"\"\n",
    "    Triages customer issues.\n",
    "    \"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    \n",
    "    prompt = f\"\"\"Categorize this customer issue: {query}\n",
    "    \n",
    "    Categories: billing, technical, account, general\n",
    "    Respond with ONLY the category.\"\"\"\n",
    "    \n",
    "    category = watsonx_llm.invoke(prompt).strip().lower()\n",
    "    \n",
    "    print(f\"\\nüìû Triage: Issue categorized as '{category}'\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"Issue triaged\")],\n",
    "        \"issue_category\": category\n",
    "    }\n",
    "\n",
    "\n",
    "def resolution_agent(state: SupportState) -> SupportState:\n",
    "    \"\"\"\n",
    "    Provides solutions to customer issues.\n",
    "    \"\"\"\n",
    "    query = state[\"customer_query\"]\n",
    "    category = state[\"issue_category\"]\n",
    "    \n",
    "    prompt = f\"\"\"Provide a helpful solution for this {category} issue:\n",
    "    {query}\n",
    "    \n",
    "    Be specific and actionable.\"\"\"\n",
    "    \n",
    "    solution = watsonx_llm.invoke(prompt)\n",
    "    \n",
    "    print(\"\\n‚úÖ Resolution: Solution provided\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Solution generated\")],\n",
    "        \"solution\": solution,\n",
    "        \"escalation_needed\": False\n",
    "    }\n",
    "\n",
    "\n",
    "# Build support workflow\n",
    "support_workflow = StateGraph(SupportState)\n",
    "support_workflow.add_node(\"triage\", triage_agent)\n",
    "support_workflow.add_node(\"resolution\", resolution_agent)\n",
    "\n",
    "support_workflow.set_entry_point(\"triage\")\n",
    "support_workflow.add_edge(\"triage\", \"resolution\")\n",
    "support_workflow.add_edge(\"resolution\", END)\n",
    "\n",
    "support_app = support_workflow.compile()\n",
    "\n",
    "print(\"\\n‚úÖ Customer Support System ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Customer Support System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the support system\n",
    "customer_issue = \"I can't log into my account after resetting my password\"\n",
    "\n",
    "print(f\"\\nüé´ Customer Issue: {customer_issue}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "support_result = support_app.invoke({\n",
    "    \"messages\": [HumanMessage(content=customer_issue)],\n",
    "    \"customer_query\": customer_issue,\n",
    "    \"issue_category\": \"\",\n",
    "    \"solution\": \"\",\n",
    "    \"escalation_needed\": False\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã SUPPORT SOLUTION\")\n",
    "print(\"=\"*60)\n",
    "print(support_result[\"solution\"])\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Best Practices & Tips\n",
    "\n",
    "### ‚úÖ Do's:\n",
    "\n",
    "1. **Clear State Definition**: Define explicit state structures for your agents\n",
    "2. **Specialized Agents**: Create focused agents with specific responsibilities\n",
    "3. **Error Handling**: Add try-catch blocks for robust production systems\n",
    "4. **Logging**: Track agent execution for debugging\n",
    "5. **Testing**: Test individual agents before integrating\n",
    "\n",
    "### ‚ùå Don'ts:\n",
    "\n",
    "1. **Avoid Circular Dependencies**: Ensure your graph has clear flow\n",
    "2. **Don't Overload Agents**: Keep agent responsibilities focused\n",
    "3. **Don't Ignore State**: Always pass complete state information\n",
    "\n",
    "### üéØ Performance Tips:\n",
    "\n",
    "- Use appropriate model parameters (temperature, max_tokens)\n",
    "- Cache results when possible\n",
    "- Implement parallel execution for independent agents\n",
    "- Monitor token usage\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion & Next Steps\n",
    "\n",
    "### What We've Learned:\n",
    "\n",
    "1. ‚úÖ LangGraph fundamentals and architecture\n",
    "2. ‚úÖ Integrating watsonx.ai with LangGraph\n",
    "3. ‚úÖ Building single-agent systems\n",
    "4. ‚úÖ Creating multi-agent workflows\n",
    "5. ‚úÖ Implementing conditional routing\n",
    "6. ‚úÖ Real-world applications\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Experiment**: Try different agent configurations\n",
    "2. **Extend**: Add more specialized agents\n",
    "3. **Deploy**: Move to production with proper error handling\n",
    "4. **Optimize**: Fine-tune prompts and parameters\n",
    "5. **Scale**: Implement parallel execution and caching\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [LangGraph Documentation](https://python.langchain.com/docs/langgraph)\n",
    "- [Watsonx.ai Documentation](https://www.ibm.com/docs/en/watsonx-as-a-service)\n",
    "- [LangChain IBM Integration](https://python.langchain.com/docs/integrations/providers/ibm)\n",
    "\n",
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the Watsonx.ai + LangGraph Multi-Agent Tutorial!\n",
    "\n",
    "Feel free to experiment with the code and build your own multi-agent systems.\n",
    "\n",
    "---\n",
    "\n",
    "### üìù Practice Exercise\n",
    "\n",
    "Try creating your own multi-agent system for:\n",
    "- Content moderation pipeline\n",
    "- Data analysis workflow\n",
    "- Educational tutoring system\n",
    "- Code review automation\n",
    "\n",
    "**Happy Building! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
