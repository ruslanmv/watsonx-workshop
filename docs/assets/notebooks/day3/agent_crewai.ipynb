{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 3.2 - Agentic AI with CrewAI + watsonx.ai\n",
        "\n",
        "This notebook demonstrates how to build a multi-agent system using CrewAI with watsonx.ai as the LLM backend.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- How to integrate watsonx.ai models with CrewAI\n",
        "- Creating custom tools for agents (RAG service and calculator)\n",
        "- Building a collaborative agent system\n",
        "- Using agents to solve complex tasks\n",
        "\n",
        "## Architecture\n",
        "\n",
        "1. **watsonx.ai** - IBM's foundation model platform (Granite models)\n",
        "2. **CrewAI** - Multi-agent orchestration framework\n",
        "3. **Custom Tools** - RAG service and calculator tools\n",
        "4. **Accelerator RAG API** - Backend RAG service for knowledge retrieval\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "### Google Colab Compatibility\n",
        "\n",
        "This notebook is designed to work both locally and in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"✓ Running in Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"✓ Running in local environment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q crewai crewai-tools requests \"ibm-watsonx-ai>=1.1.22\" langchain-ibm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure watsonx.ai Credentials\n",
        "\n",
        "To use watsonx.ai, you need:\n",
        "\n",
        "1. **API Key** - Get it from [IBM Cloud](https://cloud.ibm.com/iam/apikeys)\n",
        "2. **Project ID** - From your watsonx.ai project\n",
        "3. **URL** - Regional endpoint (default: us-south)\n",
        "\n",
        "### How to Get Your Credentials\n",
        "\n",
        "1. Go to [IBM Cloud](https://cloud.ibm.com)\n",
        "2. Navigate to watsonx.ai\n",
        "3. Create or open a project\n",
        "4. Copy your Project ID from the project settings\n",
        "5. Create an API key from IBM Cloud IAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Configuration for watsonx.ai\n",
        "WATSONX_URL = os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\")\n",
        "\n",
        "if not os.getenv(\"WATSONX_APIKEY\"):\n",
        "    WATSONX_APIKEY = getpass(\"Enter your watsonx.ai API Key: \")\n",
        "else:\n",
        "    WATSONX_APIKEY = os.getenv(\"WATSONX_APIKEY\")\n",
        "\n",
        "if not os.getenv(\"WATSONX_PROJECT_ID\"):\n",
        "    WATSONX_PROJECT_ID = getpass(\"Enter your watsonx.ai Project ID: \")\n",
        "else:\n",
        "    WATSONX_PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
        "\n",
        "# Model configuration\n",
        "LLM_MODEL_ID = os.getenv(\"LLM_MODEL_ID\", \"ibm/granite-3-8b-instruct\")\n",
        "\n",
        "# Accelerator API URL (set this to your RAG service endpoint)\n",
        "ACCELERATOR_API_URL = os.getenv(\"ACCELERATOR_API_URL\", \"http://localhost:8000/ask\")\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"  Model: {LLM_MODEL_ID}\")\n",
        "print(f\"  URL: {WATSONX_URL}\")\n",
        "print(f\"  RAG API: {ACCELERATOR_API_URL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize watsonx.ai LLM for CrewAI\n",
        "\n",
        "CrewAI can work with LangChain-compatible LLMs. We'll use the IBM watsonx.ai integration through LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_ibm import WatsonxLLM\n",
        "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
        "\n",
        "# Configure model parameters\n",
        "model_params = {\n",
        "    \"decoding_method\": \"greedy\",\n",
        "    \"max_new_tokens\": 1000,\n",
        "    \"min_new_tokens\": 1,\n",
        "    \"temperature\": 0.5,\n",
        "    \"top_k\": 50,\n",
        "    \"top_p\": 1\n",
        "}\n",
        "\n",
        "# Initialize watsonx.ai LLM\n",
        "watsonx_llm = WatsonxLLM(\n",
        "    model_id=LLM_MODEL_ID,\n",
        "    url=WATSONX_URL,\n",
        "    apikey=WATSONX_APIKEY,\n",
        "    project_id=WATSONX_PROJECT_ID,\n",
        "    params=model_params\n",
        ")\n",
        "\n",
        "print(\"✓ watsonx.ai LLM initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Custom Tools\n",
        "\n",
        "We'll create two tools for our agents:\n",
        "\n",
        "1. **RAG Service Tool** - Queries the accelerator RAG API for knowledge retrieval\n",
        "2. **Calculator Tool** - Performs safe arithmetic calculations\n",
        "\n",
        "These tools give our agents the ability to access external knowledge and perform computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import ast\n",
        "import operator as op\n",
        "from typing import Any\n",
        "import requests\n",
        "from crewai_tools import tool\n",
        "\n",
        "@tool(\"rag_service_tool\")\n",
        "def rag_service_tool(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Query the RAG (Retrieval-Augmented Generation) service to answer questions\n",
        "    based on enterprise knowledge base.\n",
        "    \n",
        "    Use this tool when you need to:\n",
        "    - Answer questions about specific documents or knowledge\n",
        "    - Retrieve factual information from the knowledge base\n",
        "    - Get context-aware responses based on enterprise data\n",
        "    \n",
        "    Args:\n",
        "        question: The question to ask the RAG service\n",
        "    \n",
        "    Returns:\n",
        "        Formatted string containing the answer and citations\n",
        "    \"\"\"\n",
        "    try:\n",
        "        payload = {\"question\": question}\n",
        "        resp = requests.post(ACCELERATOR_API_URL, json=payload, timeout=60)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        \n",
        "        answer = data.get(\"answer\") or data.get(\"result\") or \"No answer available\"\n",
        "        citations = data.get(\"citations\") or data.get(\"chunks\") or []\n",
        "        \n",
        "        result = f\"ANSWER: {answer}\\n\"\n",
        "        if citations:\n",
        "            result += f\"\\nCITATIONS: {json.dumps(citations, indent=2)}\"\n",
        "        \n",
        "        return result\n",
        "    except Exception as e:\n",
        "        return f\"Error calling RAG service: {str(e)}\"\n",
        "\n",
        "\n",
        "# Safe calculator implementation using AST\n",
        "_allowed_operators = {\n",
        "    ast.Add: op.add,\n",
        "    ast.Sub: op.sub,\n",
        "    ast.Mult: op.mul,\n",
        "    ast.Div: op.truediv,\n",
        "    ast.Pow: op.pow,\n",
        "}\n",
        "\n",
        "\n",
        "def _eval_ast(node):\n",
        "    \"\"\"Safely evaluate an AST node.\"\"\"\n",
        "    if isinstance(node, ast.Num):  # Python 3.7 compatibility\n",
        "        return node.n\n",
        "    if isinstance(node, ast.Constant):  # Python 3.8+\n",
        "        return node.value\n",
        "    if isinstance(node, ast.BinOp) and type(node.op) in _allowed_operators:\n",
        "        return _allowed_operators[type(node.op)](_eval_ast(node.left), _eval_ast(node.right))\n",
        "    if isinstance(node, ast.UnaryOp) and isinstance(node.op, (ast.UAdd, ast.USub)):\n",
        "        value = _eval_ast(node.operand)\n",
        "        return +value if isinstance(node.op, ast.UAdd) else -value\n",
        "    raise ValueError(\"Unsupported expression\")\n",
        "\n",
        "\n",
        "@tool(\"calculator_tool\")\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Safely evaluate arithmetic expressions.\n",
        "    \n",
        "    Use this tool when you need to:\n",
        "    - Perform mathematical calculations\n",
        "    - Evaluate arithmetic expressions\n",
        "    - Do numerical computations\n",
        "    \n",
        "    Supports: +, -, *, /, ** (power)\n",
        "    Examples: '2 + 2', '10 * (5 + 3)', '2 ** 8'\n",
        "    \n",
        "    Args:\n",
        "        expression: Mathematical expression to evaluate\n",
        "    \n",
        "    Returns:\n",
        "        Result of the calculation or error message\n",
        "    \"\"\"\n",
        "    try:\n",
        "        parsed = ast.parse(expression, mode=\"eval\")\n",
        "        result = _eval_ast(parsed.body)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating expression: {str(e)}\"\n",
        "\n",
        "\n",
        "print(\"✓ Custom tools defined successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create CrewAI Agents\n",
        "\n",
        "Now we'll create specialized agents:\n",
        "\n",
        "1. **Research Agent** - Uses RAG service to find information\n",
        "2. **Calculator Agent** - Handles mathematical computations\n",
        "\n",
        "Each agent has a specific role, goal, and backstory that guides its behavior."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "# Research Agent - specializes in information retrieval\n",
        "research_agent = Agent(\n",
        "    role=\"Research Specialist\",\n",
        "    goal=\"Find accurate and relevant information from the knowledge base to answer user questions\",\n",
        "    backstory=\"\"\"\n",
        "        You are an expert research specialist with deep knowledge of watsonx.ai and \n",
        "        enterprise AI systems. You excel at finding relevant information and providing \n",
        "        well-cited, accurate answers. You always use the RAG service to ground your \n",
        "        responses in factual data.\n",
        "    \"\"\",\n",
        "    tools=[rag_service_tool],\n",
        "    llm=watsonx_llm,\n",
        "    verbose=True,\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Calculator Agent - specializes in mathematical operations\n",
        "calculator_agent = Agent(\n",
        "    role=\"Mathematics Specialist\",\n",
        "    goal=\"Perform accurate mathematical calculations and explain the results\",\n",
        "    backstory=\"\"\"\n",
        "        You are a mathematics expert who excels at performing calculations and \n",
        "        explaining mathematical concepts. You use the calculator tool for all \n",
        "        numerical computations to ensure accuracy.\n",
        "    \"\"\",\n",
        "    tools=[calculator_tool],\n",
        "    llm=watsonx_llm,\n",
        "    verbose=True,\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Support Agent - orchestrates and delegates to specialists\n",
        "support_agent = Agent(\n",
        "    role=\"Workshop Support Coordinator\",\n",
        "    goal=\"Help users by delegating questions to the appropriate specialist agent\",\n",
        "    backstory=\"\"\"\n",
        "        You are a helpful coordinator who understands when to use the RAG service \n",
        "        for knowledge questions and when to use the calculator for math problems. \n",
        "        You have access to both tools and can decide which is most appropriate.\n",
        "    \"\"\",\n",
        "    tools=[rag_service_tool, calculator_tool],\n",
        "    llm=watsonx_llm,\n",
        "    verbose=True,\n",
        "    allow_delegation=True\n",
        ")\n",
        "\n",
        "print(\"✓ Agents created successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define Tasks and Create Crew\n",
        "\n",
        "We'll create a task that can be handled by our support agent, which will use the appropriate tool or delegate to specialist agents as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_support_task(question: str) -> Task:\n",
        "    \"\"\"\n",
        "    Create a task for the support agent to handle a user question.\n",
        "    \n",
        "    Args:\n",
        "        question: The user's question\n",
        "    \n",
        "    Returns:\n",
        "        Task object configured for the support agent\n",
        "    \"\"\"\n",
        "    return Task(\n",
        "        description=f\"\"\"\n",
        "            Answer the following user question: {question}\n",
        "            \n",
        "            Guidelines:\n",
        "            - For factual or knowledge-based questions, use the RAG service tool\n",
        "            - For mathematical calculations, use the calculator tool\n",
        "            - Provide clear, concise answers with proper citations when applicable\n",
        "            - If you use a tool, explain what tool you used and why\n",
        "        \"\"\",\n",
        "        expected_output=\"A clear, helpful answer with explanation of tools used\",\n",
        "        agent=support_agent,\n",
        "    )\n",
        "\n",
        "\n",
        "# Create the crew\n",
        "crew = Crew(\n",
        "    agents=[support_agent, research_agent, calculator_agent],\n",
        "    tasks=[],  # Tasks will be added dynamically\n",
        "    process=Process.sequential,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"✓ Crew initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test the Multi-Agent System\n",
        "\n",
        "Let's test our crew with different types of questions to see how it handles them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1: Knowledge Question (Should use RAG service)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_1 = \"What is Retrieval-Augmented Generation (RAG) and why is it important?\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER QUESTION: {question_1}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "task_1 = create_support_task(question_1)\n",
        "crew.tasks = [task_1]\n",
        "result_1 = crew.kickoff()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 2: Mathematical Question (Should use calculator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_2 = \"Calculate: (15 + 25) * 3 - 10\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER QUESTION: {question_2}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "task_2 = create_support_task(question_2)\n",
        "crew.tasks = [task_2]\n",
        "result_2 = crew.kickoff()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 3: Mixed Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_3 = \"What are the benefits of using watsonx.ai for enterprise AI?\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER QUESTION: {question_3}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "task_3 = create_support_task(question_3)\n",
        "crew.tasks = [task_3]\n",
        "result_3 = crew.kickoff()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Interactive Question Answering\n",
        "\n",
        "Now you can ask your own questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_crew(question: str):\n",
        "    \"\"\"\n",
        "    Ask a question to the crew and get an answer.\n",
        "    \n",
        "    Args:\n",
        "        question: Your question\n",
        "    \n",
        "    Returns:\n",
        "        The crew's answer\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"QUESTION: {question}\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    task = create_support_task(question)\n",
        "    crew.tasks = [task]\n",
        "    result = crew.kickoff()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ANSWER:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result)\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "# Try it out!\n",
        "# ask_crew(\"Your question here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Key Takeaways\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **watsonx.ai Integration**: We successfully integrated IBM's Granite models with CrewAI using LangChain\n",
        "2. **Custom Tools**: We created custom tools for RAG service and calculator functionality\n",
        "3. **Multi-Agent Architecture**: We built specialized agents with distinct roles and capabilities\n",
        "4. **Agent Collaboration**: Agents can work together and delegate tasks based on their expertise\n",
        "\n",
        "### Key Components\n",
        "\n",
        "- **watsonx.ai**: Foundation model platform providing Granite LLMs\n",
        "- **CrewAI**: Multi-agent orchestration framework\n",
        "- **Custom Tools**: Extensions that give agents special capabilities\n",
        "- **RAG Service**: External knowledge retrieval system\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. **Clear Agent Roles**: Define specific roles and responsibilities for each agent\n",
        "2. **Tool Selection**: Give agents only the tools they need for their role\n",
        "3. **Delegation**: Use delegation strategically to leverage specialist agents\n",
        "4. **Error Handling**: Always include proper error handling in custom tools\n",
        "5. **Documentation**: Provide clear docstrings for tools so agents understand when to use them\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try the LangGraph notebook for a different agent architecture\n",
        "- Experiment with the Langflow visual builder\n",
        "- Create your own custom tools and agents\n",
        "- Build more complex multi-agent workflows\n",
        "\n",
        "---\n",
        "\n",
        "**Course**: Multi-Agent Systems with watsonx.ai  \n",
        "**Lab**: 3.2 - CrewAI Integration  \n",
        "**Platform**: Compatible with Google Colab and local environments"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
