{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 3.2 - Agentic AI with CrewAI + watsonx.ai\n",
        "\n",
        "This notebook demonstrates how to build a multi-agent system using **CrewAI's native watsonx.ai integration**.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- How to use CrewAI's native `LLM` class with watsonx.ai (no wrappers needed!)\n",
        "- Creating custom tools for agents (RAG service and calculator)\n",
        "- Building a collaborative agent system\n",
        "- Using agents to solve complex tasks\n",
        "\n",
        "## Architecture\n",
        "\n",
        "1. **watsonx.ai** - IBM's foundation model platform (Granite models)\n",
        "2. **CrewAI** - Multi-agent orchestration framework with native watsonx.ai support\n",
        "3. **Custom Tools** - RAG service and calculator tools\n",
        "4. **Accelerator RAG API** - Backend RAG service for knowledge retrieval\n",
        "\n",
        "## Key Improvement\n",
        "\n",
        "âœ¨ **This notebook uses CrewAI's native `LLM` class** - no LangChain wrappers needed!\n",
        "\n",
        "```python\n",
        "# Old way (LangChain wrapper):\n",
        "from langchain_ibm import WatsonxLLM\n",
        "llm = WatsonxLLM(model_id=..., url=..., apikey=..., ...)\n",
        "\n",
        "# New way (CrewAI native):\n",
        "from crewai import LLM\n",
        "llm = LLM(model=\"watsonx/ibm/granite-3-8b-instruct\", api_key=..., base_url=..., ...)\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "### Google Colab Compatibility\n",
        "\n",
        "This notebook is designed to work both locally and in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"âœ“ Running in Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"âœ“ Running in local environment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "# Note: No need for langchain-ibm or ibm-watsonx-ai!\n",
        "!pip install -q crewai crewai-tools requests python-dotenv\n",
        "\n",
        "print(\"âœ… Packages installed!\")\n",
        "print(\"\\nInstalled:\")\n",
        "print(\"  - CrewAI (with native watsonx.ai support)\")\n",
        "print(\"  - CrewAI Tools\")\n",
        "print(\"  - Requests (for RAG API)\")\n",
        "print(\"  - Python-dotenv (optional)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure watsonx.ai Credentials\n",
        "\n",
        "To use watsonx.ai, you need:\n",
        "\n",
        "1. **API Key** - Get it from [IBM Cloud](https://cloud.ibm.com/iam/apikeys)\n",
        "2. **Project ID** - From your watsonx.ai project\n",
        "3. **URL** - Regional endpoint (default: us-south)\n",
        "\n",
        "### How to Get Your Credentials\n",
        "\n",
        "1. Go to [IBM Cloud](https://cloud.ibm.com)\n",
        "2. Navigate to watsonx.ai\n",
        "3. Create or open a project\n",
        "4. Copy your Project ID from the project settings\n",
        "5. Create an API key from IBM Cloud IAM\n",
        "\n",
        "### Security Best Practices\n",
        "\n",
        "- âœ… Use environment variables for credentials\n",
        "- âœ… Never commit credentials to version control\n",
        "- âœ… Use `.env` files locally (add to `.gitignore`)\n",
        "- âœ… Rotate API keys regularly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Disable CrewAI telemetry for cleaner output\n",
        "os.environ[\"CREWAI_DISABLE_TELEMETRY\"] = \"true\"\n",
        "os.environ[\"CREWAI_TELEMETRY\"] = \"false\"\n",
        "\n",
        "# Configuration for watsonx.ai\n",
        "WATSONX_URL = os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\")\n",
        "\n",
        "if not os.getenv(\"WATSONX_API_KEY\"):\n",
        "    WATSONX_API_KEY = getpass(\"Enter your watsonx.ai API Key: \")\n",
        "else:\n",
        "    WATSONX_API_KEY = os.getenv(\"WATSONX_API_KEY\")\n",
        "\n",
        "if not os.getenv(\"WATSONX_PROJECT_ID\"):\n",
        "    WATSONX_PROJECT_ID = getpass(\"Enter your watsonx.ai Project ID: \")\n",
        "else:\n",
        "    WATSONX_PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
        "\n",
        "# Store in environment for easy access\n",
        "os.environ[\"WATSONX_API_KEY\"] = WATSONX_API_KEY\n",
        "os.environ[\"WATSONX_URL\"] = WATSONX_URL\n",
        "os.environ[\"WATSONX_PROJECT_ID\"] = WATSONX_PROJECT_ID\n",
        "\n",
        "# Model configuration - Native CrewAI format!\n",
        "WATSONX_MODEL = \"watsonx/ibm/granite-3-8b-instruct\"\n",
        "\n",
        "# Accelerator API URL (set this to your RAG service endpoint)\n",
        "ACCELERATOR_API_URL = os.getenv(\"ACCELERATOR_API_URL\", \"http://localhost:8000/ask\")\n",
        "\n",
        "print(\"âœ“ Configuration loaded\")\n",
        "print(f\"  Model: {WATSONX_MODEL}\")\n",
        "print(f\"  URL: {WATSONX_URL}\")\n",
        "print(f\"  RAG API: {ACCELERATOR_API_URL}\")\n",
        "print(\"\\nâœ¨ Using CrewAI's native watsonx.ai integration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize watsonx.ai LLM with CrewAI\n",
        "\n",
        "### The Modern Way: Native Integration\n",
        "\n",
        "CrewAI now has **native support** for IBM watsonx.ai. No LangChain wrappers needed!\n",
        "\n",
        "#### Advantages:\n",
        "- âœ… **Simpler code** - No custom wrappers\n",
        "- âœ… **Fewer dependencies** - No langchain-ibm needed\n",
        "- âœ… **Better maintained** - Official CrewAI support\n",
        "- âœ… **More flexible** - Easy to customize per agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import LLM\n",
        "\n",
        "# Create watsonx.ai LLM using CrewAI's native class\n",
        "watsonx_llm = LLM(\n",
        "    model=WATSONX_MODEL,                      # Format: watsonx/provider/model\n",
        "    api_key=os.environ[\"WATSONX_API_KEY\"],\n",
        "    base_url=os.environ[\"WATSONX_URL\"],\n",
        "    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n",
        "    temperature=0.3,                           # Balanced creativity/focus\n",
        "    max_tokens=1000,                          # Maximum response length\n",
        ")\n",
        "\n",
        "print(\"âœ… watsonx.ai LLM initialized successfully!\")\n",
        "print(\"\\nðŸ“Š Configuration:\")\n",
        "print(f\"  Model: {WATSONX_MODEL}\")\n",
        "print(f\"  Temperature: 0.3 (balanced)\")\n",
        "print(f\"  Max Tokens: 1000\")\n",
        "print(\"  Integration: CrewAI Native\")\n",
        "print(\"\\nðŸŽ‰ Ready to power our agents!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Custom Tools\n",
        "\n",
        "We'll create two tools for our agents:\n",
        "\n",
        "1. **RAG Service Tool** - Queries the accelerator RAG API for knowledge retrieval\n",
        "2. **Calculator Tool** - Performs safe arithmetic calculations\n",
        "\n",
        "These tools give our agents the ability to access external knowledge and perform computations.\n",
        "\n",
        "### Tool Design Best Practices\n",
        "\n",
        "- Clear, descriptive docstrings (agents read these!)\n",
        "- Proper error handling\n",
        "- Input validation\n",
        "- Meaningful return messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import ast\n",
        "import operator as op\n",
        "from typing import Any\n",
        "import requests\n",
        "from crewai_tools import tool\n",
        "\n",
        "@tool(\"rag_service_tool\")\n",
        "def rag_service_tool(question: str) -> str:\n",
        "    \"\"\"\n",
        "    Query the RAG (Retrieval-Augmented Generation) service to answer questions\n",
        "    based on enterprise knowledge base.\n",
        "    \n",
        "    Use this tool when you need to:\n",
        "    - Answer questions about specific documents or knowledge\n",
        "    - Retrieve factual information from the knowledge base\n",
        "    - Get context-aware responses based on enterprise data\n",
        "    - Find information about watsonx.ai, RAG systems, or enterprise AI\n",
        "    \n",
        "    Args:\n",
        "        question: The question to ask the RAG service (be specific!)\n",
        "    \n",
        "    Returns:\n",
        "        Formatted string containing the answer and citations from the knowledge base\n",
        "    \"\"\"\n",
        "    try:\n",
        "        payload = {\"question\": question}\n",
        "        resp = requests.post(ACCELERATOR_API_URL, json=payload, timeout=60)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        \n",
        "        answer = data.get(\"answer\") or data.get(\"result\") or \"No answer available\"\n",
        "        citations = data.get(\"citations\") or data.get(\"chunks\") or []\n",
        "        \n",
        "        result = f\"ANSWER: {answer}\\n\"\n",
        "        if citations:\n",
        "            result += f\"\\nCITATIONS: {json.dumps(citations, indent=2)}\"\n",
        "        \n",
        "        return result\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return f\"Error connecting to RAG service: {str(e)}. Make sure ACCELERATOR_API_URL is configured correctly.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calling RAG service: {str(e)}\"\n",
        "\n",
        "\n",
        "# Safe calculator implementation using AST\n",
        "_allowed_operators = {\n",
        "    ast.Add: op.add,\n",
        "    ast.Sub: op.sub,\n",
        "    ast.Mult: op.mul,\n",
        "    ast.Div: op.truediv,\n",
        "    ast.Pow: op.pow,\n",
        "}\n",
        "\n",
        "\n",
        "def _eval_ast(node):\n",
        "    \"\"\"Safely evaluate an AST node.\"\"\"\n",
        "    if isinstance(node, ast.Num):  # Python 3.7 compatibility\n",
        "        return node.n\n",
        "    if isinstance(node, ast.Constant):  # Python 3.8+\n",
        "        return node.value\n",
        "    if isinstance(node, ast.BinOp) and type(node.op) in _allowed_operators:\n",
        "        return _allowed_operators[type(node.op)](_eval_ast(node.left), _eval_ast(node.right))\n",
        "    if isinstance(node, ast.UnaryOp) and isinstance(node.op, (ast.UAdd, ast.USub)):\n",
        "        value = _eval_ast(node.operand)\n",
        "        return +value if isinstance(node.op, ast.UAdd) else -value\n",
        "    raise ValueError(\"Unsupported expression\")\n",
        "\n",
        "\n",
        "@tool(\"calculator_tool\")\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Safely evaluate arithmetic expressions.\n",
        "    \n",
        "    Use this tool when you need to:\n",
        "    - Perform mathematical calculations\n",
        "    - Evaluate arithmetic expressions\n",
        "    - Do numerical computations\n",
        "    - Calculate totals, averages, or other numeric operations\n",
        "    \n",
        "    Supported operations: +, -, *, /, ** (power)\n",
        "    \n",
        "    Examples:\n",
        "    - Simple: '2 + 2', '10 - 5'\n",
        "    - Complex: '(15 + 25) * 3', '2 ** 8'\n",
        "    - Division: '100 / 4', '17 / 3'\n",
        "    \n",
        "    Args:\n",
        "        expression: Mathematical expression to evaluate (string)\n",
        "    \n",
        "    Returns:\n",
        "        Result of the calculation or error message\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Remove any whitespace and validate\n",
        "        expression = expression.strip()\n",
        "        if not expression:\n",
        "            return \"Error: Empty expression provided\"\n",
        "        \n",
        "        parsed = ast.parse(expression, mode=\"eval\")\n",
        "        result = _eval_ast(parsed.body)\n",
        "        return f\"Result: {result}\"\n",
        "    except SyntaxError:\n",
        "        return f\"Error: Invalid mathematical expression '{expression}'\"\n",
        "    except ZeroDivisionError:\n",
        "        return \"Error: Division by zero\"\n",
        "    except ValueError as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating expression: {str(e)}\"\n",
        "\n",
        "\n",
        "print(\"âœ… Custom tools defined successfully!\")\n",
        "print(\"\\nðŸ”§ Available Tools:\")\n",
        "print(\"  1. RAG Service Tool - Knowledge retrieval\")\n",
        "print(\"  2. Calculator Tool - Mathematical operations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Create CrewAI Agents with Native watsonx.ai LLM\n",
        "\n",
        "Now we'll create specialized agents, each powered by watsonx.ai through CrewAI's native integration:\n",
        "\n",
        "1. **Research Agent** - Uses RAG service to find information\n",
        "2. **Calculator Agent** - Handles mathematical computations\n",
        "3. **Support Agent** - Orchestrates and delegates to specialists\n",
        "\n",
        "Each agent has a specific role, goal, and backstory that guides its behavior.\n",
        "\n",
        "### Agent Design Principles\n",
        "\n",
        "- **Clear Role**: Defines what the agent does\n",
        "- **Specific Goal**: What the agent aims to achieve\n",
        "- **Rich Backstory**: Context that shapes decision-making\n",
        "- **Right Tools**: Only tools needed for the role\n",
        "- **Strategic Delegation**: When to hand off to specialists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "# Research Agent - specializes in information retrieval\n",
        "research_agent = Agent(\n",
        "    role=\"Research Specialist\",\n",
        "    goal=\"Find accurate and relevant information from the knowledge base to answer user questions\",\n",
        "    backstory=\"\"\"\n",
        "        You are an expert research specialist with deep knowledge of watsonx.ai and \n",
        "        enterprise AI systems. You excel at finding relevant information and providing \n",
        "        well-cited, accurate answers. You always use the RAG service to ground your \n",
        "        responses in factual data from the knowledge base.\n",
        "    \"\"\",\n",
        "    tools=[rag_service_tool],\n",
        "    llm=watsonx_llm,  # Powered by watsonx.ai natively!\n",
        "    verbose=True,\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Calculator Agent - specializes in mathematical operations\n",
        "calculator_agent = Agent(\n",
        "    role=\"Mathematics Specialist\",\n",
        "    goal=\"Perform accurate mathematical calculations and explain the results clearly\",\n",
        "    backstory=\"\"\"\n",
        "        You are a mathematics expert who excels at performing calculations and \n",
        "        explaining mathematical concepts. You use the calculator tool for all \n",
        "        numerical computations to ensure 100% accuracy. You break down complex\n",
        "        calculations into steps when helpful.\n",
        "    \"\"\",\n",
        "    tools=[calculator_tool],\n",
        "    llm=watsonx_llm,  # Same LLM, different specialization!\n",
        "    verbose=True,\n",
        "    allow_delegation=False\n",
        ")\n",
        "\n",
        "# Support Agent - orchestrates and delegates to specialists\n",
        "support_agent = Agent(\n",
        "    role=\"Workshop Support Coordinator\",\n",
        "    goal=\"Help users by using the right tools or delegating to specialist agents as needed\",\n",
        "    backstory=\"\"\"\n",
        "        You are a helpful coordinator who understands when to use the RAG service \n",
        "        for knowledge questions and when to use the calculator for math problems. \n",
        "        You have access to both tools and can intelligently decide which is most \n",
        "        appropriate for each question. You're also skilled at combining results \n",
        "        from multiple tools when needed.\n",
        "    \"\"\",\n",
        "    tools=[rag_service_tool, calculator_tool],\n",
        "    llm=watsonx_llm,  # All agents use the same watsonx.ai model!\n",
        "    verbose=True,\n",
        "    allow_delegation=True  # Can delegate to specialists\n",
        ")\n",
        "\n",
        "print(\"âœ… Agents created successfully!\")\n",
        "print(\"\\nðŸ¤– Agent Team:\")\n",
        "print(\"  1. Research Specialist (RAG tool)\")\n",
        "print(\"  2. Mathematics Specialist (Calculator tool)\")\n",
        "print(\"  3. Support Coordinator (Both tools + delegation)\")\n",
        "print(\"\\nâœ¨ All powered by IBM watsonx.ai via CrewAI's native integration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Define Tasks and Create Crew\n",
        "\n",
        "We'll create a flexible task factory that can be used for any user question.\n",
        "The support agent will automatically choose the right tool or delegate to specialists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_support_task(question: str) -> Task:\n",
        "    \"\"\"\n",
        "    Create a task for the support agent to handle a user question.\n",
        "    \n",
        "    The agent will automatically:\n",
        "    - Use RAG service for knowledge questions\n",
        "    - Use calculator for mathematical questions\n",
        "    - Combine tools when needed\n",
        "    - Delegate to specialists if appropriate\n",
        "    \n",
        "    Args:\n",
        "        question: The user's question\n",
        "    \n",
        "    Returns:\n",
        "        Task object configured for the support agent\n",
        "    \"\"\"\n",
        "    return Task(\n",
        "        description=f\"\"\"\n",
        "            Answer the following user question: {question}\n",
        "            \n",
        "            Guidelines:\n",
        "            - For factual or knowledge-based questions, use the RAG service tool\n",
        "            - For mathematical calculations, use the calculator tool\n",
        "            - Provide clear, concise answers with proper citations when applicable\n",
        "            - If you use a tool, briefly explain what you found or calculated\n",
        "            - Be helpful and professional in your response\n",
        "        \"\"\",\n",
        "        expected_output=\"A clear, helpful answer with explanation of approach used\",\n",
        "        agent=support_agent,\n",
        "    )\n",
        "\n",
        "\n",
        "# Create the crew\n",
        "crew = Crew(\n",
        "    agents=[support_agent, research_agent, calculator_agent],\n",
        "    tasks=[],  # Tasks will be added dynamically\n",
        "    process=Process.sequential,\n",
        "    verbose=True,\n",
        "    memory=False,  # Disable memory for simpler demo\n",
        ")\n",
        "\n",
        "print(\"âœ… Crew initialized successfully!\")\n",
        "print(\"\\nðŸ“‹ Crew Configuration:\")\n",
        "print(\"  Process: Sequential\")\n",
        "print(\"  Agents: 3 (Support, Research, Calculator)\")\n",
        "print(\"  Memory: Disabled\")\n",
        "print(\"  Tasks: Added dynamically per question\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Test the Multi-Agent System\n",
        "\n",
        "Let's test our crew with different types of questions to see how it handles them.\n",
        "\n",
        "The support agent will automatically:\n",
        "- Choose the right tool\n",
        "- Delegate to specialists when needed\n",
        "- Combine information from multiple sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1: Knowledge Question (Should use RAG service)\n",
        "\n",
        "This question requires information retrieval from the knowledge base."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_1 = \"What is Retrieval-Augmented Generation (RAG) and why is it important?\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER QUESTION: {question_1}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nExpected behavior: Agent should use RAG service tool\\n\")\n",
        "\n",
        "task_1 = create_support_task(question_1)\n",
        "crew.tasks = [task_1]\n",
        "result_1 = crew.kickoff()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 2: Mathematical Question (Should use calculator)\n",
        "\n",
        "This question requires numerical computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_2 = \"Calculate: (15 + 25) * 3 - 10\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER QUESTION: {question_2}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nExpected behavior: Agent should use calculator tool\\n\")\n",
        "\n",
        "task_2 = create_support_task(question_2)\n",
        "crew.tasks = [task_2]\n",
        "result_2 = crew.kickoff()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 3: Enterprise AI Question\n",
        "\n",
        "A more complex question about enterprise AI systems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_3 = \"What are the benefits of using watsonx.ai for enterprise AI applications?\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER QUESTION: {question_3}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nExpected behavior: Agent should use RAG service for enterprise knowledge\\n\")\n",
        "\n",
        "task_3 = create_support_task(question_3)\n",
        "crew.tasks = [task_3]\n",
        "result_3 = crew.kickoff()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 4: Complex Calculation\n",
        "\n",
        "A more complex mathematical expression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question_4 = \"What is 2 to the power of 10, divided by 4?\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"USER QUESTION: {question_4}\")\n",
        "print(\"=\" * 80)\n",
        "print(\"\\nExpected behavior: Agent should use calculator (2**10 / 4)\\n\")\n",
        "\n",
        "task_4 = create_support_task(question_4)\n",
        "crew.tasks = [task_4]\n",
        "result_4 = crew.kickoff()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result_4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Interactive Question Answering\n",
        "\n",
        "Now you can ask your own questions!\n",
        "\n",
        "The crew will automatically:\n",
        "- Determine the question type\n",
        "- Use the appropriate tool\n",
        "- Provide well-formatted answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_crew(question: str):\n",
        "    \"\"\"\n",
        "    Ask a question to the crew and get an answer.\n",
        "    \n",
        "    Args:\n",
        "        question: Your question (can be knowledge-based or mathematical)\n",
        "    \n",
        "    Returns:\n",
        "        The crew's answer\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"QUESTION: {question}\")\n",
        "    print(\"=\" * 80)\n",
        "    print()\n",
        "    \n",
        "    task = create_support_task(question)\n",
        "    crew.tasks = [task]\n",
        "    result = crew.kickoff()\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"ANSWER:\")\n",
        "    print(\"=\" * 80)\n",
        "    print(result)\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "# Try it out!\n",
        "# Examples:\n",
        "# ask_crew(\"What is multi-agent AI?\")\n",
        "# ask_crew(\"Calculate 456 * 789\")\n",
        "# ask_crew(\"How does watsonx.ai support RAG workflows?\")\n",
        "\n",
        "print(\"âœ… Interactive function ready!\")\n",
        "print(\"\\nðŸ’¡ Try asking questions:\")\n",
        "print(\"  - Knowledge: ask_crew('What is multi-agent AI?')\")\n",
        "print(\"  - Math: ask_crew('Calculate 123 * 456')\")\n",
        "print(\"  - Complex: ask_crew('Explain watsonx.ai RAG capabilities')\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Summary and Key Takeaways\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **Native Integration**: CrewAI's `LLM` class provides seamless watsonx.ai integration\n",
        "2. **No Wrappers Needed**: Simpler, cleaner code without LangChain dependencies\n",
        "3. **Custom Tools**: Extended agent capabilities with RAG and calculator tools\n",
        "4. **Multi-Agent Architecture**: Built specialized agents with distinct roles\n",
        "5. **Agent Collaboration**: Agents work together and delegate based on expertise\n",
        "\n",
        "### Modern vs Legacy Approach\n",
        "\n",
        "```python\n",
        "# âŒ Old Way (LangChain wrapper)\n",
        "from langchain_ibm import WatsonxLLM\n",
        "llm = WatsonxLLM(\n",
        "    model_id=\"ibm/granite-3-8b-instruct\",\n",
        "    url=WATSONX_URL,\n",
        "    apikey=WATSONX_APIKEY,\n",
        "    project_id=WATSONX_PROJECT_ID,\n",
        "    params={...}\n",
        ")\n",
        "\n",
        "# âœ… New Way (CrewAI native)\n",
        "from crewai import LLM\n",
        "llm = LLM(\n",
        "    model=\"watsonx/ibm/granite-3-8b-instruct\",\n",
        "    api_key=WATSONX_API_KEY,\n",
        "    base_url=WATSONX_URL,\n",
        "    project_id=WATSONX_PROJECT_ID,\n",
        "    temperature=0.3\n",
        ")\n",
        "```\n",
        "\n",
        "### Key Components\n",
        "\n",
        "- **watsonx.ai**: IBM's foundation model platform (Granite models)\n",
        "- **CrewAI**: Multi-agent orchestration with native watsonx.ai support\n",
        "- **Custom Tools**: Extensions that give agents special capabilities\n",
        "- **RAG Service**: External knowledge retrieval system\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. **Clear Agent Roles**: Define specific roles and responsibilities\n",
        "2. **Appropriate Tools**: Give agents only the tools they need\n",
        "3. **Rich Backstories**: Provide context that shapes decision-making\n",
        "4. **Strategic Delegation**: Use delegation for complex workflows\n",
        "5. **Error Handling**: Include proper error handling in tools\n",
        "6. **Good Documentation**: Write clear docstrings for tools\n",
        "\n",
        "### Advantages of Native Integration\n",
        "\n",
        "âœ… **Fewer dependencies** - No langchain-ibm or ibm-watsonx-ai needed  \n",
        "âœ… **Simpler code** - Direct integration with CrewAI  \n",
        "âœ… **Better maintained** - Official CrewAI support  \n",
        "âœ… **More flexible** - Easy to customize per agent  \n",
        "âœ… **Production ready** - Built for enterprise use  \n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try the LangGraph notebook for a different agent architecture\n",
        "- Experiment with the Langflow visual builder\n",
        "- Create your own custom tools and agents\n",
        "- Build more complex multi-agent workflows\n",
        "- Explore different watsonx.ai models (Granite, Llama, Mixtral)\n",
        "\n",
        "---\n",
        "\n",
        "**Course**: Multi-Agent Systems with watsonx.ai  \n",
        "**Lab**: 3.2 - CrewAI Integration (Refactored)  \n",
        "**Platform**: Compatible with Google Colab and local environments  \n",
        "**Integration**: Native CrewAI LLM class (no wrappers!) âœ¨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Appendix: Quick Reference\n",
        "\n",
        "### Native watsonx.ai Model Format\n",
        "\n",
        "```python\n",
        "# Format: watsonx/provider/model-name\n",
        "\n",
        "# IBM Granite Models\n",
        "\"watsonx/ibm/granite-3-8b-instruct\"      # Efficient, balanced\n",
        "\"watsonx/ibm/granite-13b-instruct-v2\"    # Larger, more capable\n",
        "\"watsonx/ibm/granite-3-2b-instruct\"      # Smaller, faster\n",
        "\n",
        "# Meta Llama Models\n",
        "\"watsonx/meta-llama/llama-3-70b-instruct\"  # Very capable\n",
        "\"watsonx/meta-llama/llama-3-8b-instruct\"   # Efficient\n",
        "\n",
        "# Mistral Models\n",
        "\"watsonx/mistralai/mixtral-8x7b-instruct\"  # Mixture of experts\n",
        "```\n",
        "\n",
        "### Creating an LLM Instance\n",
        "\n",
        "```python\n",
        "from crewai import LLM\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"watsonx/ibm/granite-3-8b-instruct\",\n",
        "    api_key=os.environ[\"WATSONX_API_KEY\"],\n",
        "    base_url=os.environ[\"WATSONX_URL\"],\n",
        "    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n",
        "    temperature=0.3,\n",
        "    max_tokens=1000,\n",
        ")\n",
        "```\n",
        "\n",
        "### Creating an Agent\n",
        "\n",
        "```python\n",
        "from crewai import Agent\n",
        "\n",
        "agent = Agent(\n",
        "    role=\"Your Role\",\n",
        "    goal=\"Your Goal\",\n",
        "    backstory=\"Your Backstory\",\n",
        "    tools=[your_tools],\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        ")\n",
        "```\n",
        "\n",
        "### Creating a Tool\n",
        "\n",
        "```python\n",
        "from crewai_tools import tool\n",
        "\n",
        "@tool(\"tool_name\")\n",
        "def your_tool(param: str) -> str:\n",
        "    \"\"\"Clear description for the agent.\"\"\"\n",
        "    # Your tool logic\n",
        "    return result\n",
        "```\n",
        "\n",
        "### Environment Variables\n",
        "\n",
        "```bash\n",
        "WATSONX_API_KEY=your_api_key\n",
        "WATSONX_URL=https://us-south.ml.cloud.ibm.com\n",
        "WATSONX_PROJECT_ID=your_project_id\n",
        "ACCELERATOR_API_URL=http://localhost:8000/ask\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
