{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 3.1 - Building AI Agents with watsonx.ai\n",
        "\n",
        "This notebook demonstrates how to build a basic AI agent using watsonx.ai with custom tools.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- Creating a simple agent architecture with watsonx.ai\n",
        "- Implementing custom tools (RAG service and calculator)\n",
        "- Building a planner-executor agent pattern\n",
        "- Using Granite models for tool selection and answer generation\n",
        "- Handling tool execution and error cases\n",
        "\n",
        "## Agent Architecture\n",
        "\n",
        "```\n",
        "User Question\n",
        "     |\n",
        "     v\n",
        "Planner (watsonx.ai)\n",
        "  - Analyzes question\n",
        "  - Selects tool\n",
        "  - Determines arguments\n",
        "     |\n",
        "     v\n",
        "Tool Executor\n",
        "  - RAG Service\n",
        "  - Calculator\n",
        "     |\n",
        "     v\n",
        "Answer Generator (watsonx.ai)\n",
        "  - Formats tool output\n",
        "  - Generates user-friendly response\n",
        "     |\n",
        "     v\n",
        "Final Answer\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "### Google Colab Compatibility\n",
        "\n",
        "This notebook is designed to work seamlessly in both Google Colab and local environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"✓ Running in Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"✓ Running in local environment\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q \"ibm-watsonx-ai>=1.1.22\" requests pydantic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configure watsonx.ai Credentials\n",
        "\n",
        "### How to Get Your Credentials\n",
        "\n",
        "1. **API Key**:\n",
        "   - Go to [IBM Cloud](https://cloud.ibm.com/iam/apikeys)\n",
        "   - Click \"Create an IBM Cloud API key\"\n",
        "   - Copy the API key\n",
        "\n",
        "2. **Project ID**:\n",
        "   - Go to [watsonx.ai](https://dataplatform.cloud.ibm.com/wx)\n",
        "   - Open your project\n",
        "   - Click \"Manage\" → \"General\" → Copy the Project ID\n",
        "\n",
        "3. **URL**: Use regional endpoint (default: us-south)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Configuration for watsonx.ai\n",
        "WATSONX_URL = os.getenv(\"WATSONX_URL\", \"https://us-south.ml.cloud.ibm.com\")\n",
        "\n",
        "if not os.getenv(\"WATSONX_APIKEY\"):\n",
        "    WATSONX_APIKEY = getpass(\"Enter your watsonx.ai API Key: \")\n",
        "else:\n",
        "    WATSONX_APIKEY = os.getenv(\"WATSONX_APIKEY\")\n",
        "\n",
        "if not os.getenv(\"WATSONX_PROJECT_ID\"):\n",
        "    WATSONX_PROJECT_ID = getpass(\"Enter your watsonx.ai Project ID: \")\n",
        "else:\n",
        "    WATSONX_PROJECT_ID = os.getenv(\"WATSONX_PROJECT_ID\")\n",
        "\n",
        "# Model configuration\n",
        "LLM_MODEL_ID = os.getenv(\"LLM_MODEL_ID\", \"ibm/granite-3-8b-instruct\")\n",
        "\n",
        "# Accelerator API URL (update this to your RAG service endpoint)\n",
        "ACCELERATOR_API_URL = os.getenv(\"ACCELERATOR_API_URL\", \"http://localhost:8000/ask\")\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"  Model: {LLM_MODEL_ID}\")\n",
        "print(f\"  URL: {WATSONX_URL}\")\n",
        "print(f\"  RAG API: {ACCELERATOR_API_URL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Initialize watsonx.ai Model\n",
        "\n",
        "We'll create a watsonx.ai model instance for both planning and answer generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai import Credentials\n",
        "from ibm_watsonx_ai.foundation_models import Model\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
        "\n",
        "# Set up credentials\n",
        "creds = Credentials(url=WATSONX_URL, api_key=WATSONX_APIKEY)\n",
        "\n",
        "# Configure model parameters\n",
        "params = {\n",
        "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
        "    GenParams.MAX_NEW_TOKENS: 800,\n",
        "    GenParams.MIN_NEW_TOKENS: 1,\n",
        "    GenParams.TEMPERATURE: 0.3,\n",
        "    GenParams.TOP_K: 50,\n",
        "    GenParams.TOP_P: 1\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "planner_model = Model(\n",
        "    model_id=LLM_MODEL_ID,\n",
        "    credentials=creds,\n",
        "    project_id=WATSONX_PROJECT_ID,\n",
        "    params=params,\n",
        ")\n",
        "\n",
        "print(\"✓ watsonx.ai model initialized successfully\")\n",
        "\n",
        "# Test the model\n",
        "test_response = planner_model.generate_text(\"What is artificial intelligence?\")\n",
        "print(f\"\\nTest response: {test_response['results'][0]['generated_text'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Custom Tools\n",
        "\n",
        "We'll create two tools:\n",
        "\n",
        "1. **RAG Service Tool** - Queries the accelerator RAG API\n",
        "2. **Calculator Tool** - Safely evaluates arithmetic expressions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RAG Service Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import time\n",
        "from typing import Dict, Any\n",
        "\n",
        "def rag_service_tool(question: str) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Call the accelerator RAG service with a question.\n",
        "    \n",
        "    This tool retrieves information from a knowledge base using\n",
        "    Retrieval-Augmented Generation (RAG).\n",
        "    \n",
        "    Args:\n",
        "        question: The question to ask the RAG service\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary containing:\n",
        "        - answer: The RAG service answer\n",
        "        - citations: Source citations (if available)\n",
        "        - latency_ms: Response time in milliseconds\n",
        "    \"\"\"\n",
        "    payload = {\"question\": question}\n",
        "    start = time.time()\n",
        "    \n",
        "    try:\n",
        "        resp = requests.post(ACCELERATOR_API_URL, json=payload, timeout=60)\n",
        "        latency_ms = int((time.time() - start) * 1000)\n",
        "        resp.raise_for_status()\n",
        "        \n",
        "        data = resp.json()\n",
        "        data.setdefault(\"latency_ms\", latency_ms)\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"error\": str(e),\n",
        "            \"answer\": f\"Error calling RAG service: {str(e)}\",\n",
        "            \"citations\": [],\n",
        "            \"latency_ms\": int((time.time() - start) * 1000)\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"✓ RAG service tool defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculator Tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ast\n",
        "import operator as op\n",
        "\n",
        "# Safe calculator implementation using AST\n",
        "_allowed_operators = {\n",
        "    ast.Add: op.add,\n",
        "    ast.Sub: op.sub,\n",
        "    ast.Mult: op.mul,\n",
        "    ast.Div: op.truediv,\n",
        "    ast.Pow: op.pow,\n",
        "    ast.Mod: op.mod,\n",
        "}\n",
        "\n",
        "\n",
        "def _eval_ast(node):\n",
        "    \"\"\"\n",
        "    Safely evaluate an AST node.\n",
        "    \n",
        "    This prevents code injection by only allowing\n",
        "    basic arithmetic operations.\n",
        "    \"\"\"\n",
        "    if isinstance(node, ast.Num):  # Python 3.7 compatibility\n",
        "        return node.n\n",
        "    if isinstance(node, ast.Constant):  # Python 3.8+\n",
        "        return node.value\n",
        "    if isinstance(node, ast.BinOp) and type(node.op) in _allowed_operators:\n",
        "        return _allowed_operators[type(node.op)](_eval_ast(node.left), _eval_ast(node.right))\n",
        "    if isinstance(node, ast.UnaryOp) and isinstance(node.op, (ast.UAdd, ast.USub)):\n",
        "        value = _eval_ast(node.operand)\n",
        "        return +value if isinstance(node.op, ast.UAdd) else -value\n",
        "    raise ValueError(\"Unsupported expression\")\n",
        "\n",
        "\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Safely evaluate a mathematical expression.\n",
        "    \n",
        "    Supports: +, -, *, /, %, ** (power)\n",
        "    Does NOT support: variables, functions, imports\n",
        "    \n",
        "    Args:\n",
        "        expression: Mathematical expression as a string\n",
        "    \n",
        "    Returns:\n",
        "        Result as a string, or error message\n",
        "    \n",
        "    Examples:\n",
        "        >>> calculator_tool(\"2 + 2\")\n",
        "        \"4\"\n",
        "        >>> calculator_tool(\"10 * (5 + 3)\")\n",
        "        \"80\"\n",
        "    \"\"\"\n",
        "    try:\n",
        "        parsed = ast.parse(expression, mode=\"eval\")\n",
        "        result = _eval_ast(parsed.body)\n",
        "        return str(result)\n",
        "    except Exception as e:\n",
        "        return f\"Error evaluating expression: {e}\"\n",
        "\n",
        "\n",
        "print(\"✓ Calculator tool defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Build the Planner\n",
        "\n",
        "The planner uses watsonx.ai to decide which tool to use based on the user's question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel\n",
        "\n",
        "class ToolPlan(BaseModel):\n",
        "    \"\"\"\n",
        "    Schema for the planner's output.\n",
        "    \n",
        "    Attributes:\n",
        "        tool: Name of the tool to use (\"rag_service\" or \"calculator\")\n",
        "        arguments: Dictionary of arguments for the tool\n",
        "    \"\"\"\n",
        "    tool: str\n",
        "    arguments: Dict[str, Any]\n",
        "\n",
        "\n",
        "PLANNER_SYSTEM_PROMPT = \"\"\"\n",
        "You are a planner agent that decides which tool to use for a given question.\n",
        "\n",
        "Available tools:\n",
        "1. rag_service: Use this for knowledge-based questions about concepts, definitions, \n",
        "   explanations, or any question that requires accessing a knowledge base.\n",
        "   Arguments: {\"question\": \"the user's question\"}\n",
        "\n",
        "2. calculator: Use this for mathematical calculations and arithmetic operations.\n",
        "   Arguments: {\"expression\": \"mathematical expression like '2 + 2' or '10 * (5 + 3)'\"}\n",
        "\n",
        "Instructions:\n",
        "- Analyze the user's question carefully\n",
        "- Choose EXACTLY ONE tool\n",
        "- Return ONLY valid JSON with no additional text\n",
        "- Format: {\"tool\": \"tool_name\", \"arguments\": {\"arg\": \"value\"}}\n",
        "\n",
        "Decision rules:\n",
        "- If the question asks for calculation or contains math operators → use calculator\n",
        "- If the question asks \"what is\", \"explain\", \"describe\", etc. → use rag_service\n",
        "- When in doubt, prefer rag_service\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def plan_tool_call(user_input: str) -> ToolPlan:\n",
        "    \"\"\"\n",
        "    Use watsonx.ai to plan which tool to call.\n",
        "    \n",
        "    Args:\n",
        "        user_input: The user's question\n",
        "    \n",
        "    Returns:\n",
        "        ToolPlan object containing tool name and arguments\n",
        "    \"\"\"\n",
        "    user_prompt = f\"\"\"\n",
        "User question: {user_input}\n",
        "\n",
        "Respond with JSON only:\n",
        "{{\"tool\": \"tool_name\", \"arguments\": {{\"arg\": \"value\"}}}}\n",
        "\"\"\"\n",
        "    \n",
        "    prompt = f\"{PLANNER_SYSTEM_PROMPT}\\n\\n{user_prompt}\"\n",
        "    \n",
        "    # Generate response\n",
        "    raw = planner_model.generate_text(prompt=prompt)\n",
        "    text = raw[\"results\"][0][\"generated_text\"].strip()\n",
        "    \n",
        "    # Parse JSON response\n",
        "    try:\n",
        "        plan_dict = json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        # Try to extract JSON from the response\n",
        "        start = text.find(\"{\")\n",
        "        end = text.rfind(\"}\") + 1\n",
        "        if start >= 0 and end > start:\n",
        "            plan_dict = json.loads(text[start:end])\n",
        "        else:\n",
        "            # Fallback: default to RAG service\n",
        "            print(f\"Warning: Could not parse planner output, defaulting to rag_service\")\n",
        "            plan_dict = {\"tool\": \"rag_service\", \"arguments\": {\"question\": user_input}}\n",
        "    \n",
        "    return ToolPlan(**plan_dict)\n",
        "\n",
        "\n",
        "print(\"✓ Planner defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Build the Answer Generator\n",
        "\n",
        "After tool execution, we use watsonx.ai to generate a user-friendly final answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FINAL_ANSWER_SYSTEM = \"\"\"\n",
        "You are a helpful AI assistant powered by watsonx.ai.\n",
        "\n",
        "Your task is to provide a clear, concise final answer to the user based on:\n",
        "1. The original question\n",
        "2. The tool that was used\n",
        "3. The output from that tool\n",
        "\n",
        "Guidelines:\n",
        "- Be concise and direct\n",
        "- If the tool output contains an error, explain it politely and suggest alternatives\n",
        "- For RAG answers, incorporate citations if available\n",
        "- For calculator results, explain the calculation briefly\n",
        "- Maintain a helpful, professional tone\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_final_answer(user_input: str, tool_name: str, tool_output: Any) -> str:\n",
        "    \"\"\"\n",
        "    Generate a user-friendly final answer using watsonx.ai.\n",
        "    \n",
        "    Args:\n",
        "        user_input: Original user question\n",
        "        tool_name: Name of the tool that was used\n",
        "        tool_output: Output from the tool\n",
        "    \n",
        "    Returns:\n",
        "        Final answer as a string\n",
        "    \"\"\"\n",
        "    # Format tool output for the prompt\n",
        "    if isinstance(tool_output, dict):\n",
        "        tool_output_str = json.dumps(tool_output, indent=2)\n",
        "    else:\n",
        "        tool_output_str = str(tool_output)\n",
        "    \n",
        "    context = f\"\"\"\n",
        "User question: {user_input}\n",
        "\n",
        "Tool used: {tool_name}\n",
        "\n",
        "Tool output:\n",
        "{tool_output_str}\n",
        "\n",
        "Please provide a clear, helpful final answer to the user's question.\n",
        "\"\"\"\n",
        "    \n",
        "    prompt = f\"{FINAL_ANSWER_SYSTEM}\\n\\n{context}\"\n",
        "    \n",
        "    # Generate response\n",
        "    raw = planner_model.generate_text(prompt=prompt)\n",
        "    return raw[\"results\"][0][\"generated_text\"].strip()\n",
        "\n",
        "\n",
        "print(\"✓ Answer generator defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Orchestrate the Agent\n",
        "\n",
        "Now we'll tie everything together into a complete agent system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_agent_once(user_input: str, verbose: bool = True) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Run one complete agent cycle: plan → execute → answer.\n",
        "    \n",
        "    Args:\n",
        "        user_input: The user's question\n",
        "        verbose: Whether to print detailed execution info\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary containing:\n",
        "        - question: Original question\n",
        "        - tool: Tool that was used\n",
        "        - tool_args: Arguments passed to the tool\n",
        "        - tool_output: Raw tool output\n",
        "        - final_answer: Generated final answer\n",
        "        - execution_time_ms: Total execution time\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"=\" * 80)\n",
        "        print(f\"USER QUESTION: {user_input}\")\n",
        "        print(\"=\" * 80)\n",
        "    \n",
        "    # Step 1: Plan which tool to use\n",
        "    if verbose:\n",
        "        print(\"\\n[1/3] Planning...\")\n",
        "    \n",
        "    plan = plan_tool_call(user_input)\n",
        "    tool_name = plan.tool\n",
        "    args = plan.arguments or {}\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"  → Selected tool: {tool_name}\")\n",
        "        print(f\"  → Arguments: {json.dumps(args, indent=4)}\")\n",
        "    \n",
        "    # Step 2: Execute the tool\n",
        "    if verbose:\n",
        "        print(\"\\n[2/3] Executing tool...\")\n",
        "    \n",
        "    if tool_name == \"rag_service\":\n",
        "        question = args.get(\"question\") or user_input\n",
        "        tool_output = rag_service_tool(question)\n",
        "    elif tool_name == \"calculator\":\n",
        "        expr = args.get(\"expression\") or user_input\n",
        "        tool_output = calculator_tool(expr)\n",
        "    else:\n",
        "        tool_output = f\"Unknown tool: {tool_name}\"\n",
        "    \n",
        "    if verbose:\n",
        "        if isinstance(tool_output, dict):\n",
        "            print(f\"  → Tool output: {json.dumps(tool_output, indent=4)[:200]}...\")\n",
        "        else:\n",
        "            print(f\"  → Tool output: {str(tool_output)[:200]}\")\n",
        "    \n",
        "    # Step 3: Generate final answer\n",
        "    if verbose:\n",
        "        print(\"\\n[3/3] Generating final answer...\")\n",
        "    \n",
        "    final_answer = generate_final_answer(user_input, tool_name, tool_output)\n",
        "    \n",
        "    execution_time_ms = int((time.time() - start_time) * 1000)\n",
        "    \n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(\"FINAL ANSWER:\")\n",
        "        print(\"=\" * 80)\n",
        "        print(final_answer)\n",
        "        print(\"\\n\" + \"=\" * 80)\n",
        "        print(f\"Execution time: {execution_time_ms}ms\")\n",
        "        print(\"=\" * 80)\n",
        "    \n",
        "    return {\n",
        "        \"question\": user_input,\n",
        "        \"tool\": tool_name,\n",
        "        \"tool_args\": args,\n",
        "        \"tool_output\": tool_output,\n",
        "        \"final_answer\": final_answer,\n",
        "        \"execution_time_ms\": execution_time_ms\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"✓ Agent orchestration defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Test the Agent\n",
        "\n",
        "Let's test our agent with different types of questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 1: Knowledge Question (RAG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_1 = run_agent_once(\"What is Retrieval-Augmented Generation and why do we use it?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 2: Mathematical Question (Calculator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_2 = run_agent_once(\"What is 2 * (3 + 4)?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test 3: Another Knowledge Question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result_3 = run_agent_once(\"Explain the benefits of using watsonx.ai for enterprise AI\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Batch Testing\n",
        "\n",
        "Test multiple questions and analyze the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_questions = [\n",
        "    \"What is RAG and why do we use it?\",\n",
        "    \"Calculate 15 * 8 + 20\",\n",
        "    \"What are the key features of IBM Granite models?\",\n",
        "    \"Compute (100 - 25) / 5\",\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BATCH TESTING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n[Test {i}/{len(test_questions)}]\")\n",
        "    result = run_agent_once(question, verbose=False)\n",
        "    results.append(result)\n",
        "    print(f\"Q: {question}\")\n",
        "    print(f\"Tool: {result['tool']}\")\n",
        "    print(f\"A: {result['final_answer'][:150]}...\")\n",
        "    print(f\"Time: {result['execution_time_ms']}ms\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Total questions: {len(results)}\")\n",
        "print(f\"RAG calls: {sum(1 for r in results if r['tool'] == 'rag_service')}\")\n",
        "print(f\"Calculator calls: {sum(1 for r in results if r['tool'] == 'calculator')}\")\n",
        "print(f\"Avg execution time: {sum(r['execution_time_ms'] for r in results) // len(results)}ms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Interactive Mode\n",
        "\n",
        "Ask your own questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def ask_agent(question: str):\n",
        "    \"\"\"\n",
        "    Simple interface to ask the agent a question.\n",
        "    \n",
        "    Args:\n",
        "        question: Your question\n",
        "    \n",
        "    Returns:\n",
        "        The agent's answer\n",
        "    \"\"\"\n",
        "    result = run_agent_once(question, verbose=True)\n",
        "    return result['final_answer']\n",
        "\n",
        "\n",
        "# Try it out!\n",
        "# ask_agent(\"Your question here\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Summary and Key Takeaways\n",
        "\n",
        "### What We Built\n",
        "\n",
        "1. **Planner-Executor Agent Pattern**: A two-stage agent that first plans, then executes\n",
        "2. **Custom Tools**: RAG service and calculator with proper error handling\n",
        "3. **JSON-based Communication**: Structured communication between planner and executor\n",
        "4. **Answer Generation**: LLM-powered final answer formatting\n",
        "\n",
        "### Key Components\n",
        "\n",
        "- **Planner**: Uses watsonx.ai to decide which tool to use\n",
        "- **Tools**: Extensible tool system (RAG and calculator)\n",
        "- **Executor**: Runs the selected tool with appropriate arguments\n",
        "- **Generator**: Creates user-friendly final answers\n",
        "\n",
        "### Advantages of This Approach\n",
        "\n",
        "1. **Explicit Tool Selection**: Clear decision-making process\n",
        "2. **Extensibility**: Easy to add new tools\n",
        "3. **Error Handling**: Robust error management at each step\n",
        "4. **Auditability**: Complete execution trace for debugging\n",
        "5. **Flexibility**: Can adapt to different use cases\n",
        "\n",
        "### Limitations\n",
        "\n",
        "1. **Single Tool**: Can only use one tool per question\n",
        "2. **No Memory**: Doesn't remember previous interactions\n",
        "3. **No Iteration**: Can't retry or refine answers\n",
        "4. **Fixed Tools**: Tool list is hardcoded\n",
        "\n",
        "### Extending This Agent\n",
        "\n",
        "To make this agent more powerful, you could:\n",
        "\n",
        "1. **Add More Tools**:\n",
        "   - Web search\n",
        "   - Database query\n",
        "   - File operations\n",
        "   - API calls\n",
        "\n",
        "2. **Add Memory**:\n",
        "   - Conversation history\n",
        "   - User preferences\n",
        "   - Session state\n",
        "\n",
        "3. **Multi-Step Planning**:\n",
        "   - Use multiple tools in sequence\n",
        "   - Implement chain-of-thought reasoning\n",
        "   - Add reflection and self-correction\n",
        "\n",
        "4. **Better Tool Selection**:\n",
        "   - Fine-tune the planner model\n",
        "   - Add few-shot examples\n",
        "   - Implement confidence scoring\n",
        "\n",
        "### Comparison with Other Approaches\n",
        "\n",
        "| Feature | Basic Agent | CrewAI | LangGraph |\n",
        "|---------|-------------|--------|----------|\n",
        "| Complexity | Low | Medium | Medium-High |\n",
        "| Tool Support | Manual | Built-in | Built-in |\n",
        "| Multi-Agent | No | Yes | Yes |\n",
        "| State Management | Manual | Automatic | Explicit |\n",
        "| Learning Curve | Easy | Medium | Medium |\n",
        "| Flexibility | High | Medium | Very High |\n",
        "\n",
        "### Best Practices\n",
        "\n",
        "1. **Clear Tool Descriptions**: Help the planner make better decisions\n",
        "2. **Structured Prompts**: Use consistent prompt formats\n",
        "3. **Error Handling**: Always handle tool failures gracefully\n",
        "4. **Logging**: Track all decisions for debugging\n",
        "5. **Testing**: Test with diverse question types\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try the **CrewAI notebook** for multi-agent collaboration\n",
        "- Explore **LangGraph** for complex stateful workflows\n",
        "- Experiment with **Langflow** for visual agent building\n",
        "- Build your own custom tools and agents\n",
        "\n",
        "---\n",
        "\n",
        "**Course**: Multi-Agent Systems with watsonx.ai  \n",
        "**Lab**: 3.1 - Basic Agent with watsonx.ai  \n",
        "**Platform**: Compatible with Google Colab and local environments"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
