{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üêù IBM watsonx.ai + BeeAI Framework Workshop\n",
        "\n",
        "---\n",
        "\n",
        "## Workshop Overview\n",
        "\n",
        "Welcome to this comprehensive hands-on workshop where you'll learn to build intelligent multi-agent systems using **IBM watsonx.ai** and the **BeeAI Framework**!\n",
        "\n",
        "### What is BeeAI?\n",
        "\n",
        "BeeAI is a powerful open-source framework for building agent-based AI workflows. It provides:\n",
        "- ü§ñ **Multi-agent orchestration** with specialized roles\n",
        "- üîß **Built-in tools** for web search, weather, and more\n",
        "- üîÑ **Workflow management** with sequential and parallel execution\n",
        "- üìä **Event-driven architecture** for monitoring and control\n",
        "- üéØ **Production-ready** patterns for enterprise applications\n",
        "\n",
        "### What You'll Learn\n",
        "\n",
        "By the end of this workshop, you will be able to:\n",
        "\n",
        "1. ‚úÖ Set up BeeAI framework with watsonx.ai\n",
        "2. ‚úÖ Create intelligent agents with specialized roles\n",
        "3. ‚úÖ Integrate tools (Wikipedia, Weather, Custom APIs)\n",
        "4. ‚úÖ Build multi-agent workflows with dependencies\n",
        "5. ‚úÖ Handle events and monitor agent execution\n",
        "6. ‚úÖ Implement real-world use cases\n",
        "\n",
        "### Prerequisites\n",
        "\n",
        "- Python 3.10 or higher\n",
        "- IBM Cloud account with watsonx.ai access\n",
        "- Basic understanding of async/await in Python\n",
        "- Familiarity with AI agents (helpful but not required)\n",
        "\n",
        "### What You'll Need\n",
        "\n",
        "Before starting, ensure you have:\n",
        "\n",
        "- üîë **IBM Cloud API Key** for watsonx.ai\n",
        "- üåê **watsonx.ai Service URL** (e.g., `https://us-south.ml.cloud.ibm.com`)\n",
        "- üìÅ **Project ID** from your watsonx.ai project\n",
        "\n",
        "> üí° **New to watsonx.ai?** Visit [IBM Cloud](https://cloud.ibm.com) to create your instance.\n",
        "\n",
        "---\n",
        "\n",
        "### Workshop Structure\n",
        "\n",
        "| Section | Topic | Duration |\n",
        "|---------|-------|----------|\n",
        "| 0 | Environment Setup | 5 min |\n",
        "| 1 | BeeAI + watsonx.ai Integration | 10 min |\n",
        "| 2 | Creating Your First Agent | 10 min |\n",
        "| 3 | Working with Tools | 15 min |\n",
        "| 4 | Multi-Agent Workflows | 20 min |\n",
        "| 5 | Event Handling & Monitoring | 15 min |\n",
        "| 6 | Real-World Use Cases | 20 min |\n",
        "| 7 | Advanced Patterns | 15 min |\n",
        "| 8 | Exercises & Challenges | 20 min |\n",
        "\n",
        "---\n",
        "\n",
        "**Let's build intelligent agents! üöÄ**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section0"
      },
      "source": [
        "---\n",
        "\n",
        "## üì¶ Section 0: Environment Setup\n",
        "\n",
        "### Installing BeeAI Framework\n",
        "\n",
        "We'll install the BeeAI framework and its dependencies. BeeAI provides a clean, modular architecture for building agent-based systems.\n",
        "\n",
        "### What We're Installing\n",
        "\n",
        "- **beeai-framework**: Core framework for agent orchestration\n",
        "- **ibm-watsonx-ai**: IBM watsonx.ai SDK\n",
        "- **python-dotenv**: Environment variable management\n",
        "- **httpx**: Modern HTTP client for async operations\n",
        "\n",
        "> ‚è±Ô∏è Installation takes approximately 2-3 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "# Install BeeAI Framework and dependencies\n",
        "!pip install -q beeai-framework ibm-watsonx-ai python-dotenv httpx\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "print(\"\\nüìö Installed Components:\")\n",
        "print(\"  - BeeAI Framework (agent orchestration)\")\n",
        "print(\"  - IBM watsonx.ai SDK (LLM backend)\")\n",
        "print(\"  - Python-dotenv (configuration)\")\n",
        "print(\"  - HTTPX (async HTTP client)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "version_check"
      },
      "source": [
        "### Verify Installation\n",
        "\n",
        "Let's check that everything is installed correctly and display version information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_versions"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import platform\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ENVIRONMENT INFORMATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Python Version: {sys.version.split()[0]}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "print()\n",
        "\n",
        "# Check installed packages\n",
        "packages = {\n",
        "    \"beeai_framework\": \"BeeAI Framework\",\n",
        "    \"ibm_watsonx_ai\": \"IBM watsonx.ai SDK\",\n",
        "    \"httpx\": \"HTTPX\",\n",
        "}\n",
        "\n",
        "for module_name, display_name in packages.items():\n",
        "    try:\n",
        "        module = __import__(module_name)\n",
        "        version = getattr(module, \"__version__\", \"installed\")\n",
        "        print(f\"‚úÖ {display_name}: {version}\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå {display_name}: Not installed - {e}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"Environment ready for BeeAI + watsonx.ai!\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section1"
      },
      "source": [
        "---\n",
        "\n",
        "## üîê Section 1: watsonx.ai Configuration & BeeAI Integration\n",
        "\n",
        "### Understanding the Architecture\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   BeeAI Framework       ‚îÇ\n",
        "‚îÇ   - AgentWorkflow       ‚îÇ\n",
        "‚îÇ   - Agent Management    ‚îÇ\n",
        "‚îÇ   - Tool Integration    ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "            ‚îÇ\n",
        "            ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   ChatModel Interface   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "            ‚îÇ\n",
        "            ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   watsonx.ai API        ‚îÇ\n",
        "‚îÇ   - Granite Models      ‚îÇ\n",
        "‚îÇ   - LLama Models        ‚îÇ\n",
        "‚îÇ   - Custom Models       ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### watsonx.ai Connection Setup\n",
        "\n",
        "BeeAI connects to watsonx.ai through environment variables. Let's configure these securely.\n",
        "\n",
        "#### Required Environment Variables\n",
        "\n",
        "- `WATSONX_API_KEY`: Your IBM Cloud API key\n",
        "- `WATSONX_URL`: Service endpoint URL\n",
        "- `WATSONX_PROJECT_ID`: Your project identifier\n",
        "\n",
        "### Security Best Practices üõ°Ô∏è\n",
        "\n",
        "- ‚úÖ Never hardcode credentials\n",
        "- ‚úÖ Use environment variables\n",
        "- ‚úÖ Mask sensitive input with `getpass`\n",
        "- ‚úÖ Rotate API keys regularly\n",
        "- ‚úÖ Use project-scoped access"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "configure_credentials"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "print(\"üîê watsonx.ai Configuration Setup\")\n",
        "print(\"=\"*70)\n",
        "print(\"Your credentials will be stored securely as environment variables.\")\n",
        "print(\"They will NOT be displayed or saved to disk.\\n\")\n",
        "\n",
        "# Securely collect credentials\n",
        "WATSONX_API_KEY = getpass(\"Enter your IBM Cloud API Key: \")\n",
        "\n",
        "print(\"\\nCommon watsonx.ai URLs by region:\")\n",
        "print(\"  US South (Dallas):  https://us-south.ml.cloud.ibm.com\")\n",
        "print(\"  EU DE (Frankfurt):  https://eu-de.ml.cloud.ibm.com\")\n",
        "print(\"  EU GB (London):     https://eu-gb.ml.cloud.ibm.com\")\n",
        "print(\"  JP TOK (Tokyo):     https://jp-tok.ml.cloud.ibm.com\")\n",
        "WATSONX_URL = input(\"\\nEnter your watsonx.ai URL: \").strip()\n",
        "\n",
        "WATSONX_PROJECT_ID = input(\"Enter your Project ID: \").strip()\n",
        "\n",
        "# Set environment variables for BeeAI\n",
        "os.environ[\"WATSONX_API_KEY\"] = WATSONX_API_KEY\n",
        "os.environ[\"WATSONX_APIKEY\"] = WATSONX_API_KEY\n",
        "os.environ[\"WATSONX_URL\"] = WATSONX_URL\n",
        "os.environ[\"WATSONX_PROJECT_ID\"] = WATSONX_PROJECT_ID\n",
        "\n",
        "print(\"\\n‚úÖ Configuration complete!\")\n",
        "print(f\"   Region: {WATSONX_URL}\")\n",
        "print(f\"   Project: {WATSONX_PROJECT_ID[:8]}...\")\n",
        "print(\"\\nüîí Credentials are now available to BeeAI framework.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_connection"
      },
      "source": [
        "### Test watsonx.ai Connection\n",
        "\n",
        "Let's verify that BeeAI can successfully connect to watsonx.ai by creating a simple ChatModel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_watsonx_connection"
      },
      "outputs": [],
      "source": [
        "from beeai_framework.backend.chat import ChatModel\n",
        "from beeai_framework.backend.message import UserMessage\n",
        "\n",
        "# Available watsonx models in BeeAI\n",
        "AVAILABLE_MODELS = [\n",
        "    \"watsonx:granite-13b-instruct-v2\",\n",
        "    \"watsonx:granite-13b-chat-v2\",\n",
        "    \"watsonx:granite-3-8b-instruct\",\n",
        "    \"watsonx:llama-3-70b-instruct\",\n",
        "    \"watsonx:mixtral-8x7b-instruct\",\n",
        "]\n",
        "\n",
        "print(\"ü§ñ Available watsonx.ai Models in BeeAI:\")\n",
        "for model in AVAILABLE_MODELS:\n",
        "    print(f\"   - {model}\")\n",
        "\n",
        "# Select default model\n",
        "MODEL_ID = \"watsonx:granite-13b-instruct-v2\"\n",
        "print(f\"\\nüìç Using model: {MODEL_ID}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    # Initialize the ChatModel\n",
        "    llm = ChatModel.from_name(MODEL_ID)\n",
        "    \n",
        "    print(\"‚è≥ Testing connection to watsonx.ai...\\n\")\n",
        "    \n",
        "    # Test with a simple message\n",
        "    import asyncio\n",
        "    \n",
        "    async def test_connection():\n",
        "        response = await llm.generate(messages=[\n",
        "            UserMessage(content=\"Say hello and confirm you're powered by IBM watsonx.ai!\")\n",
        "        ])\n",
        "        return response.message.content\n",
        "    \n",
        "    # Run the async test\n",
        "    result = await test_connection()\n",
        "    \n",
        "    print(\"‚úÖ CONNECTION SUCCESSFUL!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Response from watsonx.ai:\\n\")\n",
        "    print(result)\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nüéâ BeeAI is successfully connected to watsonx.ai!\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(\"‚ùå CONNECTION FAILED\")\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"\\nTroubleshooting:\")\n",
        "    print(\"  1. Verify your API key is correct\")\n",
        "    print(\"  2. Check that your URL matches your region\")\n",
        "    print(\"  3. Ensure your Project ID is valid\")\n",
        "    print(\"  4. Confirm the model is available in your instance\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section2"
      },
      "source": [
        "---\n",
        "\n",
        "## ü§ñ Section 2: Creating Your First BeeAI Agent\n",
        "\n",
        "### What is a BeeAI Agent?\n",
        "\n",
        "A BeeAI agent is an autonomous AI entity with:\n",
        "- **Name**: Unique identifier\n",
        "- **Role**: Its function in the system\n",
        "- **Instructions**: How it should behave\n",
        "- **Tools**: Capabilities it can use (optional)\n",
        "- **LLM**: The language model powering it\n",
        "\n",
        "### Agent Design Philosophy\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ         AGENT                  ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
        "‚îÇ  ‚îÇ Name: \"Researcher\"       ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îÇ Role: Information Finder ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
        "‚îÇ                                ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
        "‚îÇ  ‚îÇ Instructions:            ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îÇ \"Find accurate info...\"  ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
        "‚îÇ                                ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
        "‚îÇ  ‚îÇ Tools:                   ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îÇ - Wikipedia              ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îÇ - Web Search             ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
        "‚îÇ                                ‚îÇ\n",
        "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
        "‚îÇ  ‚îÇ LLM: watsonx.ai          ‚îÇ  ‚îÇ\n",
        "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### Creating a Simple Agent\n",
        "\n",
        "Let's create our first agent - a helpful assistant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "first_agent"
      },
      "outputs": [],
      "source": [
        "from beeai_framework.workflows.agent import AgentWorkflow, AgentWorkflowInput\n",
        "from beeai_framework.backend.chat import ChatModel\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "\n",
        "# Create a workflow (container for agents)\n",
        "workflow = AgentWorkflow(name=\"My First Workflow\")\n",
        "\n",
        "# Add a simple assistant agent\n",
        "workflow.add_agent(\n",
        "    name=\"Assistant\",\n",
        "    role=\"A helpful AI assistant\",\n",
        "    instructions=(\n",
        "        \"You are a friendly and knowledgeable assistant. \"\n",
        "        \"Provide clear, concise, and helpful responses. \"\n",
        "        \"Be professional yet approachable.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ First agent created successfully!\")\n",
        "print(\"=\"*70)\n",
        "print(\"Agent Details:\")\n",
        "print(\"  Name: Assistant\")\n",
        "print(\"  Role: A helpful AI assistant\")\n",
        "print(\"  Powered by: watsonx.ai Granite 13B\")\n",
        "print(\"  Tools: None (basic conversation)\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_first_agent"
      },
      "source": [
        "### Test Your First Agent\n",
        "\n",
        "Let's give the agent a task and see how it responds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_first_agent"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "\n",
        "async def test_assistant():\n",
        "    print(\"üß™ Testing Assistant Agent...\\n\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # Run the workflow with a simple prompt\n",
        "    response = await workflow.run(\n",
        "        inputs=[\n",
        "            AgentWorkflowInput(\n",
        "                prompt=\"Explain what BeeAI framework is in 3 sentences.\",\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    print(\"\\n‚úÖ AGENT RESPONSE:\")\n",
        "    print(\"=\"*70)\n",
        "    print(response.result.final_answer)\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nüéâ Your first agent is working!\")\n",
        "\n",
        "# Run the test\n",
        "await test_assistant()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section3"
      },
      "source": [
        "---\n",
        "\n",
        "## üîß Section 3: Working with Tools\n",
        "\n",
        "### What are Tools?\n",
        "\n",
        "Tools extend agent capabilities beyond text generation. BeeAI provides built-in tools for:\n",
        "\n",
        "- üìö **Wikipedia**: Access encyclopedic knowledge\n",
        "- üå§Ô∏è **Weather (OpenMeteo)**: Get real-time weather data\n",
        "- üîç **Web Search**: Search the internet\n",
        "- üßÆ **Calculator**: Perform calculations\n",
        "- üóÑÔ∏è **Database**: Query databases\n",
        "- üîå **Custom Tools**: Build your own!\n",
        "\n",
        "### Tool Architecture\n",
        "\n",
        "```\n",
        "Agent receives task\n",
        "      |\n",
        "      ‚ñº\n",
        "Decides if tool needed\n",
        "      |\n",
        "      ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Tool Execution ‚îÇ\n",
        "‚îÇ  - Wikipedia    ‚îÇ\n",
        "‚îÇ  - Weather      ‚îÇ\n",
        "‚îÇ  - Custom       ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "         |\n",
        "         ‚ñº\n",
        "   Process results\n",
        "         |\n",
        "         ‚ñº\n",
        "   Generate response\n",
        "```\n",
        "\n",
        "### Creating Tool-Enabled Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agents_with_tools"
      },
      "outputs": [],
      "source": [
        "from beeai_framework.workflows.agent import AgentWorkflow, AgentWorkflowInput\n",
        "from beeai_framework.backend.chat import ChatModel\n",
        "from beeai_framework.tools.search.wikipedia import WikipediaTool\n",
        "from beeai_framework.tools.weather.openmeteo import OpenMeteoTool\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "\n",
        "# Create a new workflow with tool-enabled agents\n",
        "tools_workflow = AgentWorkflow(name=\"Research and Weather Assistant\")\n",
        "\n",
        "# Agent 1: Wikipedia Researcher\n",
        "tools_workflow.add_agent(\n",
        "    name=\"WikiResearcher\",\n",
        "    role=\"An expert researcher specializing in encyclopedic knowledge\",\n",
        "    instructions=(\n",
        "        \"You are a diligent researcher who uses Wikipedia to find accurate, \"\n",
        "        \"well-sourced information. Always provide clear, factual summaries. \"\n",
        "        \"If information isn't available, say so clearly.\"\n",
        "    ),\n",
        "    tools=[WikipediaTool()],\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "# Agent 2: Weather Expert\n",
        "tools_workflow.add_agent(\n",
        "    name=\"WeatherExpert\",\n",
        "    role=\"A meteorologist providing weather forecasts\",\n",
        "    instructions=(\n",
        "        \"You are a professional meteorologist. Provide detailed weather reports \"\n",
        "        \"including temperature, conditions, precipitation, and wind. Present data \"\n",
        "        \"clearly and professionally. Only report available information.\"\n",
        "    ),\n",
        "    tools=[OpenMeteoTool()],\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Tool-enabled agents created!\")\n",
        "print(\"=\"*70)\n",
        "print(\"Agent 1: WikiResearcher\")\n",
        "print(\"  Tool: Wikipedia API\")\n",
        "print(\"  Capability: Search and retrieve encyclopedia articles\")\n",
        "print()\n",
        "print(\"Agent 2: WeatherExpert\")\n",
        "print(\"  Tool: OpenMeteo API\")\n",
        "print(\"  Capability: Get real-time weather data for any location\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_tools"
      },
      "source": [
        "### Test Wikipedia Tool\n",
        "\n",
        "Let's test the Wikipedia researcher agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_wikipedia"
      },
      "outputs": [],
      "source": [
        "async def test_wikipedia_agent():\n",
        "    print(\"üìö Testing Wikipedia Researcher...\\n\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    response = await tools_workflow.run(\n",
        "        inputs=[\n",
        "            AgentWorkflowInput(\n",
        "                prompt=\"Provide a brief summary of artificial intelligence, including its history and main applications.\",\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    print(\"\\n‚úÖ WIKIPEDIA RESEARCH RESULT:\")\n",
        "    print(\"=\"*70)\n",
        "    print(response.result.final_answer)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "await test_wikipedia_agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "test_weather"
      },
      "source": [
        "### Test Weather Tool\n",
        "\n",
        "Now let's test the weather expert agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test_weather_tool"
      },
      "outputs": [],
      "source": [
        "async def test_weather_agent():\n",
        "    print(\"üå§Ô∏è Testing Weather Expert...\\n\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    # You can change this to any city!\n",
        "    CITY = \"Paris\"\n",
        "    \n",
        "    response = await tools_workflow.run(\n",
        "        inputs=[\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"What is the current weather in {CITY}? Include temperature, conditions, and any warnings.\",\n",
        "                expected_output=\"A comprehensive weather report with all available data.\"\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n‚úÖ WEATHER REPORT FOR {CITY.upper()}:\")\n",
        "    print(\"=\"*70)\n",
        "    print(response.result.final_answer)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "await test_weather_agent()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section4"
      },
      "source": [
        "---\n",
        "\n",
        "## üë• Section 4: Building Multi-Agent Workflows\n",
        "\n",
        "### The Power of Agent Collaboration\n",
        "\n",
        "Multi-agent workflows enable:\n",
        "- **Specialization**: Each agent focuses on what it does best\n",
        "- **Sequential Processing**: Agents build on each other's work\n",
        "- **Complex Problem Solving**: Break down big tasks into manageable steps\n",
        "- **Quality Assurance**: Multiple perspectives improve results\n",
        "\n",
        "### Workflow Pattern: Research ‚Üí Analysis ‚Üí Synthesis\n",
        "\n",
        "```\n",
        "Input: \"Analyze Paris weather and tourism\"\n",
        "         |\n",
        "         ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Step 1: Research    ‚îÇ ‚Üê WikiResearcher\n",
        "‚îÇ Gather facts about  ‚îÇ   (Wikipedia Tool)\n",
        "‚îÇ Paris tourism       ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Step 2: Weather     ‚îÇ ‚Üê WeatherExpert\n",
        "‚îÇ Get current weather ‚îÇ   (OpenMeteo Tool)\n",
        "‚îÇ conditions          ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ Step 3: Synthesize  ‚îÇ ‚Üê Synthesizer\n",
        "‚îÇ Combine research &  ‚îÇ   (No tools)\n",
        "‚îÇ weather into report ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "           ‚îÇ\n",
        "           ‚ñº\n",
        "     Final Report\n",
        "```\n",
        "\n",
        "### Building a Complete Multi-Agent System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "multi_agent_workflow"
      },
      "outputs": [],
      "source": [
        "from beeai_framework.workflows.agent import AgentWorkflow, AgentWorkflowInput\n",
        "from beeai_framework.backend.chat import ChatModel\n",
        "from beeai_framework.tools.search.wikipedia import WikipediaTool\n",
        "from beeai_framework.tools.weather.openmeteo import OpenMeteoTool\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "\n",
        "# Create a comprehensive workflow\n",
        "smart_assistant = AgentWorkflow(name=\"Smart Travel Assistant\")\n",
        "\n",
        "# Agent 1: Historical Researcher\n",
        "smart_assistant.add_agent(\n",
        "    name=\"HistoricalResearcher\",\n",
        "    role=\"A knowledgeable historian and cultural expert\",\n",
        "    instructions=(\n",
        "        \"You are an expert in history and culture. When asked about a location, \"\n",
        "        \"provide fascinating historical context, cultural significance, and \"\n",
        "        \"interesting facts. Make your research engaging and informative.\"\n",
        "    ),\n",
        "    tools=[WikipediaTool()],\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "# Agent 2: Weather Analyst\n",
        "smart_assistant.add_agent(\n",
        "    name=\"WeatherAnalyst\",\n",
        "    role=\"A professional meteorologist and climate analyst\",\n",
        "    instructions=(\n",
        "        \"You provide detailed, accurate weather information. Include temperature, \"\n",
        "        \"precipitation probability, wind conditions, and any relevant alerts. \"\n",
        "        \"Present data in a clear, organized format suitable for travelers.\"\n",
        "    ),\n",
        "    tools=[OpenMeteoTool()],\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "# Agent 3: Travel Advisor (Synthesizer)\n",
        "smart_assistant.add_agent(\n",
        "    name=\"TravelAdvisor\",\n",
        "    role=\"An experienced travel consultant and content synthesizer\",\n",
        "    instructions=(\n",
        "        \"You are a skilled travel advisor who combines historical and weather \"\n",
        "        \"information into comprehensive travel recommendations. Create engaging, \"\n",
        "        \"well-structured reports that help travelers make informed decisions. \"\n",
        "        \"Highlight key points and provide practical advice.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Multi-Agent Workflow Created!\")\n",
        "print(\"=\"*70)\n",
        "print(\"Workflow: Smart Travel Assistant\")\n",
        "print()\n",
        "print(\"Agent Pipeline:\")\n",
        "print(\"  1. HistoricalResearcher ‚Üí Gathers cultural/historical context\")\n",
        "print(\"  2. WeatherAnalyst ‚Üí Provides current weather data\")\n",
        "print(\"  3. TravelAdvisor ‚Üí Synthesizes into travel recommendations\")\n",
        "print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "run_workflow"
      },
      "source": [
        "### Execute the Multi-Agent Workflow\n",
        "\n",
        "Now let's run our complete workflow with all three agents working together.\n",
        "\n",
        "> ‚è±Ô∏è This may take 30-60 seconds as each agent completes its task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "execute_workflow"
      },
      "outputs": [],
      "source": [
        "async def run_smart_assistant():\n",
        "    # Choose your destination!\n",
        "    DESTINATION = \"Barcelona\"\n",
        "    \n",
        "    print(f\"üåç Analyzing destination: {DESTINATION}\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Starting multi-agent workflow...\\n\")\n",
        "    \n",
        "    # Run the workflow with sequential tasks\n",
        "    response = await smart_assistant.run(\n",
        "        inputs=[\n",
        "            # Step 1: Historical Research\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"Provide a comprehensive overview of {DESTINATION}, including its history, culture, and main attractions.\",\n",
        "            ),\n",
        "            \n",
        "            # Step 2: Weather Analysis\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"Provide a detailed weather report for {DESTINATION} today, including temperature, conditions, and any travel advisories.\",\n",
        "                expected_output=\"Complete weather data with temperature, precipitation, wind, and conditions.\"\n",
        "            ),\n",
        "            \n",
        "            # Step 3: Travel Synthesis\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"Create a comprehensive travel guide for {DESTINATION} that combines the historical information and current weather conditions.\",\n",
        "                expected_output=(\n",
        "                    f\"A well-structured travel guide with sections for: \"\n",
        "                    f\"(1) Destination Overview, (2) Current Weather, \"\n",
        "                    f\"(3) What to Expect, (4) Travel Tips\"\n",
        "                )\n",
        "            ),\n",
        "        ]\n",
        "    ).on(\n",
        "        \"success\",\n",
        "        lambda data, event: print(\n",
        "            f\"\\n{'='*70}\\n\"\n",
        "            f\"‚úÖ Step '{data.step}' completed\\n\"\n",
        "            f\"{'='*70}\\n\"\n",
        "            f\"{data.state.final_answer}\\n\"\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üéâ WORKFLOW COMPLETE - FINAL TRAVEL GUIDE\")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "    print(response.result.final_answer)\n",
        "    print()\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Execute the workflow\n",
        "await run_smart_assistant()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section5"
      },
      "source": [
        "---\n",
        "\n",
        "## üìä Section 5: Event Handling & Monitoring\n",
        "\n",
        "### Understanding BeeAI Events\n",
        "\n",
        "BeeAI provides an event-driven architecture for monitoring and controlling workflow execution.\n",
        "\n",
        "### Available Events\n",
        "\n",
        "- **success**: Fired when a step completes successfully\n",
        "- **error**: Fired when an error occurs\n",
        "- **start**: Fired when workflow begins\n",
        "- **finish**: Fired when workflow completes\n",
        "- **agent_start**: Fired when an agent begins processing\n",
        "- **agent_finish**: Fired when an agent completes\n",
        "\n",
        "### Event-Driven Monitoring Pattern\n",
        "\n",
        "```\n",
        "Workflow Execution\n",
        "        |\n",
        "        ‚ñº\n",
        "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "   ‚îÇ  Event  ‚îÇ\n",
        "   ‚îÇ  Bus    ‚îÇ\n",
        "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "        |\n",
        "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "   ‚îÇ                  ‚îÇ\n",
        "   ‚ñº                  ‚ñº\n",
        "Success            Error\n",
        "Handler           Handler\n",
        "   ‚îÇ                  ‚îÇ\n",
        "   ‚ñº                  ‚ñº\n",
        "Logging         Error Recovery\n",
        "Metrics         Notifications\n",
        "```\n",
        "\n",
        "### Implementing Event Handlers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "event_handling"
      },
      "outputs": [],
      "source": [
        "from beeai_framework.workflows.agent import AgentWorkflow, AgentWorkflowInput\n",
        "from beeai_framework.backend.chat import ChatModel\n",
        "import time\n",
        "\n",
        "# Create workflow with event monitoring\n",
        "llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "monitored_workflow = AgentWorkflow(name=\"Monitored Workflow\")\n",
        "\n",
        "# Add a simple agent\n",
        "monitored_workflow.add_agent(\n",
        "    name=\"AnalystAgent\",\n",
        "    role=\"A data analyst\",\n",
        "    instructions=\"Analyze the given information and provide insights.\",\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "# Event tracking\n",
        "event_log = []\n",
        "start_time = None\n",
        "\n",
        "def log_event(event_type: str, message: str):\n",
        "    \"\"\"Helper to log events with timestamps\"\"\"\n",
        "    timestamp = time.strftime(\"%H:%M:%S\")\n",
        "    event_log.append({\"time\": timestamp, \"type\": event_type, \"message\": message})\n",
        "    print(f\"[{timestamp}] {event_type}: {message}\")\n",
        "\n",
        "async def run_monitored_workflow():\n",
        "    global start_time\n",
        "    start_time = time.time()\n",
        "    \n",
        "    print(\"üìä Starting Monitored Workflow\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"Event tracking enabled...\\n\")\n",
        "    \n",
        "    try:\n",
        "        response = await monitored_workflow.run(\n",
        "            inputs=[\n",
        "                AgentWorkflowInput(\n",
        "                    prompt=\"Analyze the benefits of using multi-agent systems in enterprise AI.\",\n",
        "                )\n",
        "            ]\n",
        "        ).on(\n",
        "            \"success\",\n",
        "            lambda data, event: log_event(\n",
        "                \"SUCCESS\",\n",
        "                f\"Step '{data.step}' completed with {len(str(data.state.final_answer))} characters\"\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"üìà WORKFLOW METRICS\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Total Duration: {elapsed:.2f} seconds\")\n",
        "        print(f\"Events Logged: {len(event_log)}\")\n",
        "        print(f\"Response Length: {len(response.result.final_answer)} characters\")\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "        print(\"\\nüìã EVENT LOG:\")\n",
        "        for event in event_log:\n",
        "            print(f\"  [{event['time']}] {event['type']}: {event['message']}\")\n",
        "        \n",
        "        print(\"\\n‚úÖ FINAL RESULT:\")\n",
        "        print(\"=\"*70)\n",
        "        print(response.result.final_answer)\n",
        "        print(\"=\"*70)\n",
        "        \n",
        "    except Exception as e:\n",
        "        log_event(\"ERROR\", f\"Workflow failed: {str(e)}\")\n",
        "        print(f\"\\n‚ùå Error occurred: {e}\")\n",
        "\n",
        "await run_monitored_workflow()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section6"
      },
      "source": [
        "---\n",
        "\n",
        "## üíº Section 6: Real-World Use Cases\n",
        "\n",
        "Let's build practical multi-agent systems for real business scenarios.\n",
        "\n",
        "### Use Case 1: Customer Support Automation\n",
        "\n",
        "**Scenario**: Automate customer inquiry handling with intelligent routing\n",
        "\n",
        "**Agents**:\n",
        "1. **Classifier**: Categorizes customer inquiries\n",
        "2. **Responder**: Generates appropriate responses\n",
        "3. **Quality Checker**: Validates response quality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "use_case_support"
      },
      "outputs": [],
      "source": [
        "from beeai_framework.workflows.agent import AgentWorkflow, AgentWorkflowInput\n",
        "from beeai_framework.backend.chat import ChatModel\n",
        "\n",
        "llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "\n",
        "# Create customer support workflow\n",
        "support_system = AgentWorkflow(name=\"Customer Support AI\")\n",
        "\n",
        "# Agent 1: Inquiry Classifier\n",
        "support_system.add_agent(\n",
        "    name=\"Classifier\",\n",
        "    role=\"Customer inquiry classification specialist\",\n",
        "    instructions=(\n",
        "        \"You classify customer inquiries into categories: Technical Support, \"\n",
        "        \"Billing, Product Information, Complaints, or General Questions. \"\n",
        "        \"Analyze the inquiry and provide the category with a brief explanation.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "# Agent 2: Response Generator\n",
        "support_system.add_agent(\n",
        "    name=\"Responder\",\n",
        "    role=\"Customer service response specialist\",\n",
        "    instructions=(\n",
        "        \"You generate professional, helpful customer service responses. \"\n",
        "        \"Be empathetic, clear, and solution-oriented. Address the specific \"\n",
        "        \"category of inquiry appropriately. Keep responses concise but complete.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "# Agent 3: Quality Assurance\n",
        "support_system.add_agent(\n",
        "    name=\"QualityChecker\",\n",
        "    role=\"Response quality assurance specialist\",\n",
        "    instructions=(\n",
        "        \"You review customer service responses for quality. Check for: \"\n",
        "        \"(1) Professionalism, (2) Clarity, (3) Completeness, (4) Empathy. \"\n",
        "        \"If issues exist, suggest improvements. Otherwise, approve the response.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "async def handle_customer_inquiry(inquiry: str):\n",
        "    print(f\"üìß Processing Customer Inquiry\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Inquiry: {inquiry}\\n\")\n",
        "    \n",
        "    response = await support_system.run(\n",
        "        inputs=[\n",
        "            # Step 1: Classify\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"Classify this customer inquiry: '{inquiry}'\",\n",
        "            ),\n",
        "            # Step 2: Generate Response\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"Generate a professional response to this inquiry: '{inquiry}'\",\n",
        "            ),\n",
        "            # Step 3: Quality Check\n",
        "            AgentWorkflowInput(\n",
        "                prompt=\"Review the response for quality and approve or suggest improvements.\",\n",
        "            ),\n",
        "        ]\n",
        "    ).on(\n",
        "        \"success\",\n",
        "        lambda data, event: print(\n",
        "            f\"‚úÖ {data.step} completed\\n\"\n",
        "        )\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üì§ FINAL APPROVED RESPONSE\")\n",
        "    print(\"=\"*70)\n",
        "    print(response.result.final_answer)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Test with a sample inquiry\n",
        "sample_inquiry = \"I've been trying to log into my account for two days but keep getting an error message. Can you help?\"\n",
        "await handle_customer_inquiry(sample_inquiry)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "use_case_content"
      },
      "source": [
        "### Use Case 2: Content Creation Pipeline\n",
        "\n",
        "**Scenario**: Automated content generation with quality control\n",
        "\n",
        "**Agents**:\n",
        "1. **Researcher**: Gathers information on topic\n",
        "2. **Writer**: Creates engaging content\n",
        "3. **Editor**: Polishes and fact-checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "use_case_content_code"
      },
      "outputs": [],
      "source": [
        "from beeai_framework.workflows.agent import AgentWorkflow, AgentWorkflowInput\n",
        "from beeai_framework.backend.chat import ChatModel\n",
        "from beeai_framework.tools.search.wikipedia import WikipediaTool\n",
        "\n",
        "llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "\n",
        "# Create content creation pipeline\n",
        "content_pipeline = AgentWorkflow(name=\"Content Creation System\")\n",
        "\n",
        "content_pipeline.add_agent(\n",
        "    name=\"Researcher\",\n",
        "    role=\"Technical content researcher\",\n",
        "    instructions=\"Research topics thoroughly and provide structured, factual summaries.\",\n",
        "    tools=[WikipediaTool()],\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "content_pipeline.add_agent(\n",
        "    name=\"Writer\",\n",
        "    role=\"Technical content writer\",\n",
        "    instructions=(\n",
        "        \"Create engaging, informative blog posts from research. \"\n",
        "        \"Use clear structure with introduction, main points, and conclusion. \"\n",
        "        \"Make it accessible to a technical audience.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "content_pipeline.add_agent(\n",
        "    name=\"Editor\",\n",
        "    role=\"Content editor and fact-checker\",\n",
        "    instructions=(\n",
        "        \"Review content for accuracy, clarity, and engagement. \"\n",
        "        \"Fix any errors, improve flow, and ensure technical correctness. \"\n",
        "        \"Output the polished final version.\"\n",
        "    ),\n",
        "    llm=llm,\n",
        ")\n",
        "\n",
        "async def create_blog_post(topic: str):\n",
        "    print(f\"‚úçÔ∏è Creating Blog Post: {topic}\")\n",
        "    print(\"=\"*70)\n",
        "    \n",
        "    response = await content_pipeline.run(\n",
        "        inputs=[\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"Research: {topic}\",\n",
        "            ),\n",
        "            AgentWorkflowInput(\n",
        "                prompt=f\"Write a 300-word blog post about: {topic}\",\n",
        "            ),\n",
        "            AgentWorkflowInput(\n",
        "                prompt=\"Edit and finalize the blog post.\",\n",
        "            ),\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üìù PUBLISHED BLOG POST\")\n",
        "    print(\"=\"*70)\n",
        "    print(response.result.final_answer)\n",
        "    print(\"=\"*70)\n",
        "\n",
        "# Create a blog post\n",
        "await create_blog_post(\"The Future of Multi-Agent AI Systems\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section7"
      },
      "source": [
        "---\n",
        "\n",
        "## üöÄ Section 7: Advanced Patterns\n",
        "\n",
        "### Pattern 1: Error Handling and Retry Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "error_handling"
      },
      "outputs": [],
      "source": [
        "async def robust_workflow_execution(workflow, inputs, max_retries=3):\n",
        "    \"\"\"Execute workflow with retry logic\"\"\"\n",
        "    \n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"üîÑ Attempt {attempt + 1}/{max_retries}\")\n",
        "            \n",
        "            response = await workflow.run(inputs=inputs)\n",
        "            \n",
        "            print(\"‚úÖ Workflow completed successfully\")\n",
        "            return response\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Attempt {attempt + 1} failed: {e}\")\n",
        "            \n",
        "            if attempt < max_retries - 1:\n",
        "                wait_time = 2 ** attempt  # Exponential backoff\n",
        "                print(f\"‚è≥ Waiting {wait_time}s before retry...\")\n",
        "                await asyncio.sleep(wait_time)\n",
        "            else:\n",
        "                print(\"‚ùå All retries exhausted\")\n",
        "                raise\n",
        "\n",
        "print(\"‚úÖ Robust execution function defined\")\n",
        "print(\"Use this pattern for production workflows to handle transient errors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pattern_2"
      },
      "source": [
        "### Pattern 2: Dynamic Agent Selection\n",
        "\n",
        "Choose agents based on runtime conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dynamic_agents"
      },
      "outputs": [],
      "source": [
        "def create_specialized_workflow(task_type: str):\n",
        "    \"\"\"Create workflow with agents tailored to task type\"\"\"\n",
        "    \n",
        "    llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "    workflow = AgentWorkflow(name=f\"{task_type} Workflow\")\n",
        "    \n",
        "    if task_type == \"research\":\n",
        "        workflow.add_agent(\n",
        "            name=\"Researcher\",\n",
        "            role=\"Research specialist\",\n",
        "            instructions=\"Deep research and analysis\",\n",
        "            tools=[WikipediaTool()],\n",
        "            llm=llm,\n",
        "        )\n",
        "    elif task_type == \"weather\":\n",
        "        workflow.add_agent(\n",
        "            name=\"Meteorologist\",\n",
        "            role=\"Weather expert\",\n",
        "            instructions=\"Provide weather forecasts\",\n",
        "            tools=[OpenMeteoTool()],\n",
        "            llm=llm,\n",
        "        )\n",
        "    else:\n",
        "        workflow.add_agent(\n",
        "            name=\"GeneralAssistant\",\n",
        "            role=\"General purpose assistant\",\n",
        "            instructions=\"Help with various tasks\",\n",
        "            llm=llm,\n",
        "        )\n",
        "    \n",
        "    return workflow\n",
        "\n",
        "print(\"‚úÖ Dynamic workflow creation function defined\")\n",
        "print(\"Use this pattern to optimize agent selection based on task requirements.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section8"
      },
      "source": [
        "---\n",
        "\n",
        "## üéØ Section 8: Exercises & Challenges\n",
        "\n",
        "Time to practice! Try these exercises to reinforce your learning.\n",
        "\n",
        "### Exercise 1: Modify the Destination (Easy)\n",
        "\n",
        "**Goal**: Change the travel destination in Section 4 and run the workflow again.\n",
        "\n",
        "**Instructions**:\n",
        "1. Go back to Section 4\n",
        "2. Change the `DESTINATION` variable\n",
        "3. Re-run the workflow\n",
        "\n",
        "**Try**: Rome, Tokyo, New York, London\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 2: Add a New Agent (Medium)\n",
        "\n",
        "**Goal**: Add a \"Local Expert\" agent to the travel workflow that provides insider tips.\n",
        "\n",
        "**Hints**:\n",
        "- Create agent with appropriate role and instructions\n",
        "- Add a new input step for local recommendations\n",
        "- Make it the final synthesizer\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 3: Create a Custom Tool (Advanced)\n",
        "\n",
        "**Goal**: Build a custom tool for your agents.\n",
        "\n",
        "**Ideas**:\n",
        "- Currency converter\n",
        "- Time zone calculator\n",
        "- Language translator\n",
        "- Database query tool\n",
        "\n",
        "**Resources**: Check BeeAI documentation for tool creation patterns\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 4: Build a Code Review System (Advanced)\n",
        "\n",
        "**Goal**: Create a multi-agent system for code review.\n",
        "\n",
        "**Agents Needed**:\n",
        "1. **Analyzer**: Reviews code structure and style\n",
        "2. **SecurityExpert**: Checks for security vulnerabilities\n",
        "3. **Optimizer**: Suggests performance improvements\n",
        "4. **Documenter**: Reviews code documentation\n",
        "\n",
        "**Challenge**: Make agents work sequentially, with each building on previous findings.\n",
        "\n",
        "---\n",
        "\n",
        "### Exercise 5: Implement Parallel Processing (Expert)\n",
        "\n",
        "**Goal**: Modify workflows to run some agents in parallel for better performance.\n",
        "\n",
        "**Approach**:\n",
        "- Use `asyncio.gather()` to run independent agents concurrently\n",
        "- Combine results in a final synthesis step\n",
        "\n",
        "**Use Case**: Run weather and research agents simultaneously, then synthesize.\n",
        "\n",
        "---\n",
        "\n",
        "Use the cell below for your solutions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exercise_workspace"
      },
      "outputs": [],
      "source": [
        "# üéì Exercise Workspace\n",
        "# Use this cell to complete the exercises above!\n",
        "\n",
        "# Example: Exercise 2 - Add Local Expert Agent\n",
        "\n",
        "# TODO: Your code here\n",
        "\n",
        "print(\"üí° Exercise workspace ready!\")\n",
        "print(\"Copy and adapt code from previous sections to complete challenges.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "---\n",
        "\n",
        "## üéâ Conclusion & Next Steps\n",
        "\n",
        "### What You've Accomplished\n",
        "\n",
        "Congratulations! You've successfully:\n",
        "\n",
        "‚úÖ Set up BeeAI framework with watsonx.ai  \n",
        "‚úÖ Created intelligent agents with specialized roles  \n",
        "‚úÖ Integrated tools (Wikipedia, Weather)  \n",
        "‚úÖ Built multi-agent workflows  \n",
        "‚úÖ Implemented event handling and monitoring  \n",
        "‚úÖ Developed real-world use cases  \n",
        "‚úÖ Learned advanced patterns  \n",
        "\n",
        "---\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "1. **Agent Specialization**: Focused agents produce better results than generalists\n",
        "2. **Tool Integration**: Tools extend agent capabilities beyond text generation\n",
        "3. **Workflow Orchestration**: Sequential processing enables complex problem-solving\n",
        "4. **Event Monitoring**: Essential for production deployment and debugging\n",
        "5. **watsonx.ai + BeeAI**: Powerful combination for enterprise AI solutions\n",
        "\n",
        "---\n",
        "\n",
        "### Architecture Patterns Learned\n",
        "\n",
        "```\n",
        "‚úÖ Sequential Processing\n",
        "   Agent1 ‚Üí Agent2 ‚Üí Agent3 ‚Üí Result\n",
        "\n",
        "‚úÖ Tool-Augmented Agents\n",
        "   Agent + Wikipedia + Weather ‚Üí Enhanced Capabilities\n",
        "\n",
        "‚úÖ Event-Driven Monitoring\n",
        "   Workflow ‚Üí Events ‚Üí Handlers ‚Üí Logging/Metrics\n",
        "\n",
        "‚úÖ Error Handling & Retry\n",
        "   Attempt ‚Üí Error ‚Üí Backoff ‚Üí Retry ‚Üí Success\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps & Extensions\n",
        "\n",
        "#### üîß Technical Extensions\n",
        "\n",
        "1. **Custom Tools Development**\n",
        "   - Build domain-specific tools\n",
        "   - Integrate with internal APIs\n",
        "   - Connect to databases\n",
        "\n",
        "2. **Advanced Orchestration**\n",
        "   - Parallel agent execution\n",
        "   - Conditional workflows\n",
        "   - Dynamic routing\n",
        "   - State management\n",
        "\n",
        "3. **Production Features**\n",
        "   - Comprehensive logging\n",
        "   - Performance metrics\n",
        "   - Cost tracking\n",
        "   - Error recovery\n",
        "   - Load balancing\n",
        "\n",
        "4. **Integration Patterns**\n",
        "   - REST API wrapper\n",
        "   - Message queue integration\n",
        "   - Webhook handlers\n",
        "   - Streaming responses\n",
        "\n",
        "#### üìö Learning Resources\n",
        "\n",
        "- **BeeAI**: [GitHub Repository](https://github.com/i-am-bee/beeai-framework)\n",
        "- **watsonx.ai**: [IBM Documentation](https://www.ibm.com/docs/en/watsonx-as-a-service)\n",
        "- **IBM Granite Models**: [Model Cards](https://www.ibm.com/granite)\n",
        "- **Best Practices**: [Enterprise AI Patterns](https://www.ibm.com/cloud/architecture/architectures/ai)\n",
        "\n",
        "#### üí° More Use Case Ideas\n",
        "\n",
        "1. **Business Intelligence**\n",
        "   - Automated report generation\n",
        "   - Market research analysis\n",
        "   - Competitive intelligence\n",
        "   - Trend analysis\n",
        "\n",
        "2. **Developer Productivity**\n",
        "   - Code generation and review\n",
        "   - Documentation automation\n",
        "   - Test case generation\n",
        "   - Debugging assistance\n",
        "\n",
        "3. **Customer Operations**\n",
        "   - Support ticket automation\n",
        "   - Sentiment analysis\n",
        "   - Feedback processing\n",
        "   - Proactive engagement\n",
        "\n",
        "4. **Content Operations**\n",
        "   - Multi-channel content generation\n",
        "   - Translation and localization\n",
        "   - SEO optimization\n",
        "   - Brand consistency checking\n",
        "\n",
        "---\n",
        "\n",
        "### üèóÔ∏è Building Production Systems\n",
        "\n",
        "Key considerations for production deployment:\n",
        "\n",
        "- **Scalability**: Design for concurrent requests\n",
        "- **Reliability**: Implement retry logic and fallbacks\n",
        "- **Monitoring**: Track metrics and set up alerts\n",
        "- **Security**: Secure API keys and validate inputs\n",
        "- **Cost Control**: Monitor token usage and set limits\n",
        "- **Testing**: Comprehensive unit and integration tests\n",
        "- **Documentation**: Clear API docs and runbooks\n",
        "\n",
        "---\n",
        "\n",
        "### üìû Community & Support\n",
        "\n",
        "- **Questions?** Open issues on [BeeAI GitHub](https://github.com/i-am-bee/beeai-framework)\n",
        "- **Feedback?** We'd love to hear about your use cases!\n",
        "- **Contributing?** PRs welcome to improve the framework\n",
        "- **IBM Support**: Contact IBM Cloud support for watsonx.ai assistance\n",
        "\n",
        "---\n",
        "\n",
        "### üôè Thank You!\n",
        "\n",
        "Thank you for participating in this workshop! We hope you're excited to build powerful multi-agent systems with IBM watsonx.ai and BeeAI Framework.\n",
        "\n",
        "**Remember**: The best way to learn is by building. Start with a simple use case and iterate!\n",
        "\n",
        "**Happy Building! üöÄüêù**\n",
        "\n",
        "---\n",
        "\n",
        "*This workshop was created for educational purposes. Please review IBM's usage policies and pricing before deploying to production.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appendix"
      },
      "source": [
        "---\n",
        "\n",
        "## üìé Appendix: Quick Reference\n",
        "\n",
        "### Common watsonx.ai Model IDs for BeeAI\n",
        "\n",
        "```python\n",
        "# Granite Models (IBM)\n",
        "\"watsonx:granite-13b-instruct-v2\"   # Balanced performance\n",
        "\"watsonx:granite-13b-chat-v2\"      # Optimized for chat\n",
        "\"watsonx:granite-3-8b-instruct\"    # Efficient, smaller model\n",
        "\n",
        "# Llama Models (Meta)\n",
        "\"watsonx:llama-3-70b-instruct\"     # Large, highly capable\n",
        "\"watsonx:llama-3-8b-instruct\"      # Efficient alternative\n",
        "\n",
        "# Mixtral (Mistral AI)\n",
        "\"watsonx:mixtral-8x7b-instruct\"    # Mixture of experts\n",
        "```\n",
        "\n",
        "### Essential Code Snippets\n",
        "\n",
        "#### Initialize LLM\n",
        "```python\n",
        "from beeai_framework.backend.chat import ChatModel\n",
        "llm = ChatModel.from_name(\"watsonx:granite-13b-instruct-v2\")\n",
        "```\n",
        "\n",
        "#### Create Workflow\n",
        "```python\n",
        "from beeai_framework.workflows.agent import AgentWorkflow\n",
        "workflow = AgentWorkflow(name=\"My Workflow\")\n",
        "```\n",
        "\n",
        "#### Add Agent\n",
        "```python\n",
        "workflow.add_agent(\n",
        "    name=\"AgentName\",\n",
        "    role=\"Agent role description\",\n",
        "    instructions=\"Detailed behavior instructions\",\n",
        "    tools=[],  # Optional\n",
        "    llm=llm,\n",
        ")\n",
        "```\n",
        "\n",
        "#### Run Workflow\n",
        "```python\n",
        "from beeai_framework.workflows.agent import AgentWorkflowInput\n",
        "\n",
        "response = await workflow.run(\n",
        "    inputs=[\n",
        "        AgentWorkflowInput(\n",
        "            prompt=\"Your task description\",\n",
        "            expected_output=\"Expected format\",  # Optional\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "print(response.result.final_answer)\n",
        "```\n",
        "\n",
        "#### Add Event Handler\n",
        "```python\n",
        "response = await workflow.run(inputs=inputs).on(\n",
        "    \"success\",\n",
        "    lambda data, event: print(f\"Step completed: {data.step}\")\n",
        ")\n",
        "```\n",
        "\n",
        "### Available Built-in Tools\n",
        "\n",
        "```python\n",
        "# Wikipedia\n",
        "from beeai_framework.tools.search.wikipedia import WikipediaTool\n",
        "tool = WikipediaTool()\n",
        "\n",
        "# Weather (OpenMeteo)\n",
        "from beeai_framework.tools.weather.openmeteo import OpenMeteoTool\n",
        "tool = OpenMeteoTool()\n",
        "```\n",
        "\n",
        "### Troubleshooting Guide\n",
        "\n",
        "| Issue | Possible Solution |\n",
        "|-------|------------------|\n",
        "| Authentication error | Verify WATSONX_API_KEY is set correctly |\n",
        "| Model not found | Check model ID format: `watsonx:model-name` |\n",
        "| Timeout errors | Reduce task complexity or increase timeout |\n",
        "| Import errors | Ensure `beeai-framework` is installed |\n",
        "| Async errors | Always use `await` with async functions |\n",
        "| Tool failures | Check internet connectivity and API limits |\n",
        "\n",
        "### Best Practices Checklist\n",
        "\n",
        "- ‚úÖ Use specific, clear agent instructions\n",
        "- ‚úÖ Test agents individually before combining\n",
        "- ‚úÖ Add event handlers for monitoring\n",
        "- ‚úÖ Implement error handling and retries\n",
        "- ‚úÖ Keep agent roles focused and specialized\n",
        "- ‚úÖ Use expected_output to guide agent behavior\n",
        "- ‚úÖ Log important events for debugging\n",
        "- ‚úÖ Test with various inputs\n",
        "- ‚úÖ Monitor token usage and costs\n",
        "- ‚úÖ Document your workflows\n",
        "\n",
        "---\n",
        "\n",
        "### Environment Variables Reference\n",
        "\n",
        "Required for watsonx.ai:\n",
        "```bash\n",
        "WATSONX_API_KEY=your_api_key_here\n",
        "WATSONX_URL=https://us-south.ml.cloud.ibm.com\n",
        "WATSONX_PROJECT_ID=your_project_id\n",
        "```\n",
        "\n",
        "---"
      ]
    }
  ]
}
