{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Hw3Po5d1eOgo",
      "metadata": {
        "id": "Hw3Po5d1eOgo"
      },
      "source": [
        "# IBM watsonx.ai + CrewAI Workshop (Refactored)\n",
        "\n",
        "## Modern Integration with Native CrewAI Support\n",
        "\n",
        "This notebook demonstrates:\n",
        "\n",
        "- ‚ú® **Native CrewAI `LLM` class** - No custom wrappers needed!\n",
        "- Connect to **IBM watsonx.ai** directly through CrewAI\n",
        "- Build a **multi-agent workflow** (research, writing, editing crew)\n",
        "- All powered by watsonx.ai Granite models\n",
        "\n",
        "## What Changed?\n",
        "\n",
        "```python\n",
        "# ‚ùå Old Way (Custom Wrapper)\n",
        "class WatsonxCrewAILLM(BaseLLM):\n",
        "    def __init__(self, model_id, url, ...):\n",
        "        self._chat = ChatWatsonx(...)\n",
        "    def call(self, messages, ...):\n",
        "        # Complex wrapper logic\n",
        "\n",
        "# ‚úÖ New Way (Native Integration)\n",
        "from crewai import LLM\n",
        "llm = LLM(\n",
        "    model=\"watsonx/ibm/granite-3-8b-instruct\",\n",
        "    api_key=os.getenv(\"WATSONX_API_KEY\"),\n",
        "    base_url=os.getenv(\"WATSONX_URL\"),\n",
        "    project_id=os.getenv(\"WATSONX_PROJECT_ID\")\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vkMXKTkEeOgp",
      "metadata": {
        "id": "vkMXKTkEeOgp"
      },
      "source": [
        "## 0. Prerequisites\n",
        "\n",
        "To run this notebook you need:\n",
        "\n",
        "- Python 3.10+\n",
        "- An IBM Cloud account with access to **watsonx.ai**\n",
        "- A watsonx.ai **service instance**, **project**, and **API key**\n",
        "\n",
        "> üí° Run the cells in order from top to bottom the first time.\n",
        "\n",
        "### Key Benefits of Native Integration\n",
        "\n",
        "‚úÖ **Fewer dependencies** - No langchain-ibm needed  \n",
        "‚úÖ **Simpler code** - Direct integration  \n",
        "‚úÖ **Better maintained** - Official CrewAI support  \n",
        "‚úÖ **More flexible** - Easy to customize per agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ppyrcJAPeOgp",
      "metadata": {
        "id": "ppyrcJAPeOgp"
      },
      "outputs": [],
      "source": [
        "# 1) Install required packages - SIMPLIFIED!\n",
        "# No langchain-ibm, no ibm-watsonx-ai needed!\n",
        "\n",
        "%pip install -q -U \"crewai[tools]\" python-dotenv\n",
        "\n",
        "print(\"‚úÖ Packages installed!\")\n",
        "print(\"\\nüì¶ What we installed:\")\n",
        "print(\"  - CrewAI with native watsonx.ai support\")\n",
        "print(\"  - Python-dotenv for environment variables\")\n",
        "print(\"\\n‚ú® No LangChain dependencies needed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RtZPID29eOgp",
      "metadata": {
        "id": "RtZPID29eOgp"
      },
      "outputs": [],
      "source": [
        "# 2) Quick version check\n",
        "\n",
        "import sys, platform\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"ENVIRONMENT INFORMATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Python: {sys.version.split()[0]}\")\n",
        "print(f\"Platform: {platform.platform()}\")\n",
        "print()\n",
        "\n",
        "try:\n",
        "    import crewai\n",
        "    print(f\"‚úÖ CrewAI: {crewai.__version__}\")\n",
        "    print(\"   (with native watsonx.ai support!)\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå CrewAI: {e}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"\\nüéâ Ready for native watsonx.ai integration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RVcrC1TFeOgp",
      "metadata": {
        "id": "RVcrC1TFeOgp"
      },
      "source": [
        "## 1. Configure IBM watsonx.ai Credentials\n",
        "\n",
        "You'll need three pieces of information:\n",
        "\n",
        "### 1. IBM Cloud API Key üîë\n",
        "- Get from [IBM Cloud IAM](https://cloud.ibm.com/iam/apikeys)\n",
        "- Used for authentication\n",
        "\n",
        "### 2. Service URL üåê\n",
        "Choose based on your region:\n",
        "\n",
        "| Region | URL |\n",
        "|--------|-----|\n",
        "| Dallas | `https://us-south.ml.cloud.ibm.com` |\n",
        "| Frankfurt | `https://eu-de.ml.cloud.ibm.com` |\n",
        "| London | `https://eu-gb.ml.cloud.ibm.com` |\n",
        "| Tokyo | `https://jp-tok.ml.cloud.ibm.com` |\n",
        "| Sydney | `https://au-syd.ml.cloud.ibm.com` |\n",
        "\n",
        "### 3. Project ID üìÅ\n",
        "- Found in your watsonx.ai project settings\n",
        "\n",
        "### Security Best Practices üõ°Ô∏è\n",
        "\n",
        "- ‚úÖ Use environment variables\n",
        "- ‚úÖ Never commit credentials to version control\n",
        "- ‚úÖ Rotate API keys regularly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ywZuodoyeOgq",
      "metadata": {
        "id": "ywZuodoyeOgq"
      },
      "outputs": [],
      "source": [
        "# 3) Configure watsonx.ai credentials\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Disable CrewAI telemetry for cleaner output\n",
        "os.environ[\"CREWAI_DISABLE_TELEMETRY\"] = \"true\"\n",
        "os.environ[\"CREWAI_TELEMETRY\"] = \"false\"\n",
        "\n",
        "print(\"üîê IBM watsonx.ai Credentials Setup\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get API Key (masked input)\n",
        "WATSONX_API_KEY = getpass(\"Enter your IBM Cloud API Key: \")\n",
        "\n",
        "# Get Service URL\n",
        "DEFAULT_URL = \"https://us-south.ml.cloud.ibm.com\"\n",
        "WATSONX_URL = input(f\"Enter watsonx.ai URL [{DEFAULT_URL}]: \").strip() or DEFAULT_URL\n",
        "\n",
        "# Get Project ID\n",
        "WATSONX_PROJECT_ID = input(\"Enter your Project ID: \").strip()\n",
        "\n",
        "# Store in environment variables\n",
        "os.environ[\"WATSONX_API_KEY\"] = WATSONX_API_KEY\n",
        "os.environ[\"WATSONX_URL\"] = WATSONX_URL\n",
        "os.environ[\"WATSONX_PROJECT_ID\"] = WATSONX_PROJECT_ID\n",
        "\n",
        "print(\"\\n‚úÖ Configuration complete!\")\n",
        "print(f\"   URL: {WATSONX_URL}\")\n",
        "print(f\"   Project ID: {WATSONX_PROJECT_ID[:8]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hdO__hmleOgq",
      "metadata": {
        "id": "hdO__hmleOgq"
      },
      "source": [
        "## 2. Initialize watsonx.ai with CrewAI Native Integration\n",
        "\n",
        "### The Modern Approach\n",
        "\n",
        "CrewAI now has **native watsonx.ai support** through its `LLM` class!\n",
        "\n",
        "#### Benefits:\n",
        "- ‚úÖ No custom wrapper classes\n",
        "- ‚úÖ No LangChain dependencies  \n",
        "- ‚úÖ Cleaner, more maintainable code\n",
        "- ‚úÖ Official CrewAI support\n",
        "\n",
        "#### Model Format:\n",
        "```python\n",
        "model=\"watsonx/provider/model-name\"\n",
        "\n",
        "# Examples:\n",
        "\"watsonx/ibm/granite-3-8b-instruct\"\n",
        "\"watsonx/ibm/granite-13b-instruct-v2\"\n",
        "\"watsonx/meta-llama/llama-3-70b-instruct\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T_giNWM8eOgq",
      "metadata": {
        "id": "T_giNWM8eOgq"
      },
      "outputs": [],
      "source": [
        "# 4) Initialize watsonx.ai LLM - Native CrewAI Integration!\n",
        "\n",
        "from crewai import LLM\n",
        "\n",
        "# Model configuration\n",
        "WATSONX_MODEL = \"watsonx/ibm/granite-3-8b-instruct\"\n",
        "\n",
        "print(f\"ü§ñ Initializing watsonx.ai LLM: {WATSONX_MODEL}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create the LLM instance - Simple and Clean!\n",
        "watsonx_llm = LLM(\n",
        "    model=WATSONX_MODEL,\n",
        "    api_key=os.environ[\"WATSONX_API_KEY\"],\n",
        "    base_url=os.environ[\"WATSONX_URL\"],\n",
        "    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n",
        "    temperature=0.3,\n",
        "    max_tokens=512,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ watsonx.ai LLM initialized successfully!\")\n",
        "print(\"\\nüìä Configuration:\")\n",
        "print(f\"  Model: {WATSONX_MODEL}\")\n",
        "print(f\"  Temperature: 0.3 (balanced)\")\n",
        "print(f\"  Max Tokens: 512\")\n",
        "print(\"  Integration: CrewAI Native\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n‚ú® No custom wrappers needed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "test_section",
      "metadata": {},
      "source": [
        "### Quick Connection Test\n",
        "\n",
        "Let's verify the connection works with a simple test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "test_connection",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5) Test the connection with a simple agent\n",
        "\n",
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "print(\"üß™ Testing watsonx.ai connection...\\n\")\n",
        "\n",
        "# Create a simple test agent\n",
        "test_agent = Agent(\n",
        "    role=\"Test Agent\",\n",
        "    goal=\"Verify watsonx.ai connection\",\n",
        "    backstory=\"You are a test agent powered by IBM watsonx.ai.\",\n",
        "    llm=watsonx_llm,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "# Simple test task\n",
        "test_task = Task(\n",
        "    description=\"Say hello and confirm you're powered by IBM watsonx.ai. Be brief.\",\n",
        "    expected_output=\"A short greeting.\",\n",
        "    agent=test_agent,\n",
        ")\n",
        "\n",
        "# Run test\n",
        "test_crew = Crew(\n",
        "    agents=[test_agent],\n",
        "    tasks=[test_task],\n",
        "    process=Process.sequential,\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "try:\n",
        "    result = test_crew.kickoff()\n",
        "    print(\"‚úÖ CONNECTION SUCCESSFUL!\")\n",
        "    print(\"=\"*70)\n",
        "    print(result)\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nüéâ watsonx.ai is connected and working!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Connection failed: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dn8HhEEzeOgq",
      "metadata": {
        "id": "dn8HhEEzeOgq"
      },
      "source": [
        "## 3. Building a Multi-Agent Workflow\n",
        "\n",
        "We'll build a content creation crew with three specialized agents:\n",
        "\n",
        "### Agent Pipeline\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  Researcher  ‚îÇ ‚îÄ‚îÄ‚ñ∂ Gathers structured notes\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "       ‚îÇ\n",
        "       ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   Writer     ‚îÇ ‚îÄ‚îÄ‚ñ∂ Creates tutorial content\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "       ‚îÇ\n",
        "       ‚ñº\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ   Editor     ‚îÇ ‚îÄ‚îÄ‚ñ∂ Polishes final article\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "All agents are powered by **IBM watsonx.ai** through CrewAI's native integration!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rQek3s2peOgq",
      "metadata": {
        "id": "rQek3s2peOgq"
      },
      "outputs": [],
      "source": [
        "# 6) Define the topic for our content creation crew\n",
        "\n",
        "TOPIC = \"Building multi-agent workflows with IBM watsonx.ai and CrewAI\"\n",
        "\n",
        "print(\"üìö Content Topic:\")\n",
        "print(f\"   {TOPIC}\")\n",
        "print(\"\\nüí° Tip: Change the TOPIC variable and re-run to explore different subjects!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DdiR9__ReOgr",
      "metadata": {
        "id": "DdiR9__ReOgr"
      },
      "outputs": [],
      "source": [
        "# 7) Create specialized agents using native watsonx.ai LLM\n",
        "\n",
        "from crewai import Agent\n",
        "\n",
        "# Agent 1: Researcher\n",
        "researcher = Agent(\n",
        "    role=\"AI Research Specialist\",\n",
        "    goal=\"Deeply research the given topic and produce clear, structured notes.\",\n",
        "    backstory=(\n",
        "        \"You are an expert AI research assistant with deep knowledge of IBM watsonx.ai \"\n",
        "        \"and enterprise AI systems. You excel at organizing complex information into \"\n",
        "        \"concise bullet points that are easy to understand and reuse. Your research \"\n",
        "        \"is always thorough, accurate, and well-structured.\"\n",
        "    ),\n",
        "    llm=watsonx_llm,  # Powered by watsonx.ai natively!\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Agent 2: Technical Writer\n",
        "writer = Agent(\n",
        "    role=\"Technical Writer\",\n",
        "    goal=\"Turn research notes into an engaging, practical tutorial article.\",\n",
        "    backstory=(\n",
        "        \"You are a patient technical writer who explains advanced AI concepts in \"\n",
        "        \"a way that intermediate developers can understand. You have 8 years of \"\n",
        "        \"experience creating documentation and tutorials. You know how to structure \"\n",
        "        \"content for maximum clarity and include practical examples.\"\n",
        "    ),\n",
        "    llm=watsonx_llm,  # Same LLM, different role!\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Agent 3: Editor\n",
        "editor = Agent(\n",
        "    role=\"Content Editor\",\n",
        "    goal=\"Polish content for clarity, accuracy, and workshop readiness.\",\n",
        "    backstory=(\n",
        "        \"You are a meticulous editor who focuses on correctness, structure, and \"\n",
        "        \"beginner-friendly language. You have taught hundreds of technical workshops \"\n",
        "        \"and know exactly what makes content effective for learning. You're especially \"\n",
        "        \"careful about security best practices and practical usability.\"\n",
        "    ),\n",
        "    llm=watsonx_llm,  # All agents use the same watsonx.ai model!\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print(\"‚úÖ All agents created!\")\n",
        "print(\"\\nü§ñ Agent Team:\")\n",
        "print(f\"  1. {researcher.role}\")\n",
        "print(f\"  2. {writer.role}\")\n",
        "print(f\"  3. {editor.role}\")\n",
        "print(\"\\n‚ú® All powered by IBM watsonx.ai via CrewAI's native integration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "define_tasks",
      "metadata": {},
      "source": [
        "### Define Tasks with Dependencies\n",
        "\n",
        "Each task builds on the previous one, creating a sequential workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "create_tasks",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 8) Define tasks with clear expectations\n",
        "\n",
        "from crewai import Task\n",
        "\n",
        "# Task 1: Research\n",
        "research_task = Task(\n",
        "    description=(\n",
        "        f\"Research the topic: '{TOPIC}'\\n\\n\"\n",
        "        \"Provide:\\n\"\n",
        "        \"- Overview of watsonx.ai capabilities\\n\"\n",
        "        \"- Overview of CrewAI framework\\n\"\n",
        "        \"- 6-8 practical use case ideas\\n\"\n",
        "        \"- Key benefits and considerations\\n\"\n",
        "        \"\\nFormat: Structured markdown with clear sections.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A comprehensive research document (600-800 words) with clear sections \"\n",
        "        \"and bullet points.\"\n",
        "    ),\n",
        "    agent=researcher,\n",
        ")\n",
        "\n",
        "# Task 2: Writing\n",
        "writing_task = Task(\n",
        "    description=(\n",
        "        \"Using the research notes, write a tutorial-style article.\\n\\n\"\n",
        "        \"Include:\\n\"\n",
        "        \"- Engaging introduction\\n\"\n",
        "        \"- Architecture explanation\\n\"\n",
        "        \"- Step-by-step getting started guide\\n\"\n",
        "        \"- Practical tips and pitfalls\\n\"\n",
        "        \"- Next steps\\n\"\n",
        "        \"\\nTarget: 800-1200 words, clear and practical.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A complete tutorial article with headings, short paragraphs, \"\n",
        "        \"and practical examples.\"\n",
        "    ),\n",
        "    agent=writer,\n",
        "    context=[research_task],  # Uses researcher's output\n",
        ")\n",
        "\n",
        "# Task 3: Editing\n",
        "editing_task = Task(\n",
        "    description=(\n",
        "        \"Polish the article for a professional workshop audience.\\n\\n\"\n",
        "        \"Focus on:\\n\"\n",
        "        \"- Improving clarity and flow\\n\"\n",
        "        \"- Fixing technical inaccuracies\\n\"\n",
        "        \"- Enhancing structure\\n\"\n",
        "        \"- Making security practices explicit\\n\"\n",
        "        \"- Ensuring examples are complete\\n\"\n",
        "        \"\\nFinal output should be workshop-ready.\"\n",
        "    ),\n",
        "    expected_output=(\n",
        "        \"A polished, professional article ready for workshop use. \"\n",
        "        \"Error-free and highly educational.\"\n",
        "    ),\n",
        "    agent=editor,\n",
        "    context=[writing_task],  # Uses writer's output\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Tasks defined with dependencies!\")\n",
        "print(\"\\nüìã Task Pipeline:\")\n",
        "print(\"  Research ‚Üí Writing ‚Üí Editing\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "run_crew",
      "metadata": {},
      "source": [
        "## 4. Execute the Multi-Agent Workflow\n",
        "\n",
        "Now let's run our complete workflow!\n",
        "\n",
        "> ‚è±Ô∏è **Note**: This will take 2-4 minutes as each agent completes its task sequentially."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "execute_crew",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 9) Create and execute the crew\n",
        "\n",
        "from crewai import Crew, Process\n",
        "\n",
        "# Assemble the crew\n",
        "content_crew = Crew(\n",
        "    agents=[researcher, writer, editor],\n",
        "    tasks=[research_task, writing_task, editing_task],\n",
        "    process=Process.sequential,\n",
        "    memory=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting content creation workflow...\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Topic: {TOPIC}\")\n",
        "print(\"All agents powered by IBM watsonx.ai Granite models!\")\n",
        "print(\"This will take a few minutes...\")\n",
        "print(\"=\"*70)\n",
        "print()\n",
        "\n",
        "# Execute the workflow\n",
        "result = content_crew.kickoff()\n",
        "\n",
        "# Extract final content\n",
        "final_article = str(result)\n",
        "\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"üéâ CONTENT CREATION COMPLETE!\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nüìÑ Final Article:\\n\")\n",
        "print(final_article)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"\\nüìä Article Stats:\")\n",
        "print(f\"  Length: {len(final_article)} characters\")\n",
        "print(f\"  Words: ~{len(final_article.split())}\")\n",
        "print(\"\\n‚ú® Created using CrewAI's native watsonx.ai integration!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "save_section",
      "metadata": {},
      "source": [
        "### Save the Generated Article"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "save_output",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 10) Save the article to a file\n",
        "\n",
        "output_file = \"watsonx_crewai_article.md\"\n",
        "\n",
        "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_article)\n",
        "\n",
        "print(f\"‚úÖ Article saved to: {output_file}\")\n",
        "print(\"üìÅ You can download this from the file browser.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "comparison",
      "metadata": {},
      "source": [
        "## 5. Before & After Comparison\n",
        "\n",
        "### Old Approach (Custom Wrapper)\n",
        "\n",
        "```python\n",
        "# ‚ùå Complex setup with custom wrapper\n",
        "from crewai import BaseLLM\n",
        "from langchain_ibm import ChatWatsonx\n",
        "\n",
        "class WatsonxCrewAILLM(BaseLLM):\n",
        "    def __init__(self, model_id, url, project_id, api_key, ...):\n",
        "        super().__init__(model=model_id, temperature=temperature)\n",
        "        self._chat = ChatWatsonx(\n",
        "            model_id=model_id,\n",
        "            url=url,\n",
        "            project_id=project_id,\n",
        "            params={...}\n",
        "        )\n",
        "    \n",
        "    def call(self, messages, tools, callbacks, ...):\n",
        "        # Complex message handling\n",
        "        if isinstance(messages, str):\n",
        "            chat_input = messages\n",
        "        else:\n",
        "            # Process message list...\n",
        "        result = self._chat.invoke(chat_input)\n",
        "        return getattr(result, \"content\", str(result))\n",
        "    \n",
        "    def supports_function_calling(self):\n",
        "        return False\n",
        "    \n",
        "    def get_context_window_size(self):\n",
        "        return 8192\n",
        "\n",
        "# Then use it\n",
        "llm = WatsonxCrewAILLM(\n",
        "    model_id=\"ibm/granite-3-8b-instruct\",\n",
        "    url=WATSONX_URL,\n",
        "    project_id=WATSONX_PROJECT_ID,\n",
        "    temperature=0.3,\n",
        "    max_tokens=512\n",
        ")\n",
        "```\n",
        "\n",
        "**Issues:**\n",
        "- ~50 lines of wrapper code\n",
        "- Multiple dependencies (langchain-ibm, ibm-watsonx-ai)\n",
        "- Complex message handling\n",
        "- Custom maintenance required\n",
        "\n",
        "---\n",
        "\n",
        "### New Approach (Native Integration)\n",
        "\n",
        "```python\n",
        "# ‚úÖ Simple, clean, native integration\n",
        "from crewai import LLM\n",
        "\n",
        "llm = LLM(\n",
        "    model=\"watsonx/ibm/granite-3-8b-instruct\",\n",
        "    api_key=os.environ[\"WATSONX_API_KEY\"],\n",
        "    base_url=os.environ[\"WATSONX_URL\"],\n",
        "    project_id=os.environ[\"WATSONX_PROJECT_ID\"],\n",
        "    temperature=0.3,\n",
        "    max_tokens=512,\n",
        ")\n",
        "```\n",
        "\n",
        "**Benefits:**\n",
        "- ‚úÖ 7 lines vs 50+ lines\n",
        "- ‚úÖ No custom wrapper needed\n",
        "- ‚úÖ Fewer dependencies\n",
        "- ‚úÖ Official CrewAI support\n",
        "- ‚úÖ Easier to maintain\n",
        "- ‚úÖ Better error messages\n",
        "\n",
        "---\n",
        "\n",
        "### Code Reduction Summary\n",
        "\n",
        "| Metric | Old | New | Improvement |\n",
        "|--------|-----|-----|-------------|\n",
        "| Lines of wrapper code | ~50 | 0 | -100% |\n",
        "| Dependencies | 4 | 2 | -50% |\n",
        "| LLM initialization | ~20 lines | ~7 lines | -65% |\n",
        "| Complexity | High | Low | Much simpler |\n",
        "| Maintainability | Custom | Official | Built-in support |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "experiments",
      "metadata": {},
      "source": [
        "## 6. Experiment: Try Different Topics\n",
        "\n",
        "The same crew can write about different topics. Just change the `TOPIC` variable!\n",
        "\n",
        "### Example Topics\n",
        "\n",
        "1. \"Introduction to RAG (Retrieval-Augmented Generation) with watsonx.ai\"\n",
        "2. \"Building AI Chatbots with IBM Granite Models\"\n",
        "3. \"Enterprise AI Governance and Security Best Practices\"\n",
        "4. \"Comparing Different Multi-Agent Frameworks\"\n",
        "\n",
        "To try a new topic:\n",
        "1. Scroll back to the \"Define the topic\" cell\n",
        "2. Change the `TOPIC` variable\n",
        "3. Re-run from that cell forward"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "conclusion",
      "metadata": {},
      "source": [
        "## 7. Summary & Key Takeaways\n",
        "\n",
        "### What We Learned\n",
        "\n",
        "1. **Native Integration** - CrewAI's `LLM` class provides seamless watsonx.ai support\n",
        "2. **No Wrappers Needed** - Direct integration replaces 50+ lines of custom code\n",
        "3. **Multi-Agent Workflows** - Specialized agents collaborate effectively\n",
        "4. **Sequential Processing** - Tasks build on each other's outputs\n",
        "5. **Production Ready** - Official support for enterprise deployments\n",
        "\n",
        "### Modern Integration Benefits\n",
        "\n",
        "‚úÖ **Simpler Code** - 7 lines instead of 50+  \n",
        "‚úÖ **Fewer Dependencies** - No langchain-ibm needed  \n",
        "‚úÖ **Better Maintained** - Official CrewAI support  \n",
        "‚úÖ **More Flexible** - Easy to customize  \n",
        "‚úÖ **Faster Setup** - Get started in minutes  \n",
        "\n",
        "### Architecture Pattern\n",
        "\n",
        "```\n",
        "CrewAI Agent ‚Üí Native LLM Class ‚Üí watsonx.ai API\n",
        "```\n",
        "\n",
        "No intermediate wrappers or LangChain dependencies!\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- ‚ú® Experiment with different watsonx.ai models\n",
        "- üîß Add custom tools to agents\n",
        "- üìä Build more complex workflows\n",
        "- üöÄ Deploy to production\n",
        "- üéØ Try hierarchical agent structures\n",
        "\n",
        "### Available watsonx.ai Models\n",
        "\n",
        "```python\n",
        "# IBM Granite Models\n",
        "\"watsonx/ibm/granite-3-8b-instruct\"      # Efficient, balanced\n",
        "\"watsonx/ibm/granite-13b-instruct-v2\"    # Larger, more capable\n",
        "\"watsonx/ibm/granite-3-2b-instruct\"      # Smaller, faster\n",
        "\n",
        "# Meta Llama Models  \n",
        "\"watsonx/meta-llama/llama-3-70b-instruct\"  # Very capable\n",
        "\"watsonx/meta-llama/llama-3-8b-instruct\"   # Efficient\n",
        "\n",
        "# Mistral Models\n",
        "\"watsonx/mistralai/mixtral-8x7b-instruct\"  # Mixture of experts\n",
        "```\n",
        "\n",
        "### Resources\n",
        "\n",
        "- [CrewAI Documentation](https://docs.crewai.com/)\n",
        "- [IBM watsonx.ai Documentation](https://www.ibm.com/docs/en/watsonx-as-a-service)\n",
        "- [IBM Granite Models](https://www.ibm.com/granite)\n",
        "\n",
        "---\n",
        "\n",
        "**Thank you for using this refactored notebook!**\n",
        "\n",
        "üöÄ **Happy building with watsonx.ai + CrewAI!** üöÄ\n",
        "\n",
        "---\n",
        "\n",
        "*This notebook demonstrates CrewAI's native watsonx.ai integration.  \n",
        "No custom wrappers or LangChain dependencies required!*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
