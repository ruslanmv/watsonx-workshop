{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Simple watsonx.ai Environment (Binder-ready)\n",
        "\n",
        "This notebook is a Binder-friendly version of your **simple watsonx environment**.\n",
        "\n",
        "It is designed to run in a Jupyter Notebook environment launched via\n",
        "[Binder](https://mybinder.org), but it will also work in any standard\n",
        "Jupyter environment (local, JupyterHub, etc.).\n",
        "\n",
        "## What this notebook does\n",
        "\n",
        "1. Installs the required Python libraries (`ibm-watsonx-ai`, `langchain-ibm`, `python-dotenv`).\n",
        "2. Asks you for your IBM Cloud / watsonx.ai credentials (API key, project id, URL).\n",
        "3. Runs a **quickstart** example using the native `ibm_watsonx_ai` SDK.\n",
        "4. Optionally shows how to call watsonx.ai through **LangChain**.\n",
        "\n",
        "> \u26a0\ufe0f **Security note**\n",
        ">\n",
        "> - Do **not** commit API keys into a public Git repository.\n",
        "> - When using Binder on a public repo, always enter your keys **at runtime** using the prompts in this notebook.\n",
        "> - Any `.env` file in a public repo is visible to everyone.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to launch this notebook on Binder\n",
        "\n",
        "1. Push this notebook (for example as `simple_watsonx_environment_binder.ipynb`) to a Git repository (e.g. on GitHub or GitLab).\n",
        "2. In the same repository, create a `requirements.txt` file with at least:\n",
        "\n",
        "   ```text\n",
        "   ibm-watsonx-ai\n",
        "   langchain-ibm\n",
        "   python-dotenv\n",
        "   ```\n",
        "\n",
        "3. Go to [https://mybinder.org](https://mybinder.org).\n",
        "4. Enter your repository URL and, in the **File to open** field, put the path to this notebook\n",
        "   (e.g. `simple_watsonx_environment_binder.ipynb`).\n",
        "5. Click **Launch**. Binder will build an image with your dependencies and then open Jupyter.\n",
        "6. In Jupyter, open this notebook (if it is not already opened) and run the cells from top to bottom.\n",
        "\n",
        "If you don't want to use `requirements.txt`, this notebook also contains a cell that installs\n",
        "the required libraries via `pip` at runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install-deps"
      },
      "source": [
        "# 1\ufe0f\u20e3 Install dependencies\n",
        "# If you're using Binder with a requirements.txt that already includes these\n",
        "# libraries, you can skip this cell. Otherwise, run it to install them here.\n",
        "\n",
        "!pip install -q ibm-watsonx-ai langchain-ibm python-dotenv\n",
        "print(\"\u2705 Libraries installed (or already present).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "set-credentials"
      },
      "source": [
        "# 2\ufe0f\u20e3 Configure your IBM Cloud / watsonx.ai credentials\n",
        "# These values live only in the current notebook kernel.\n",
        "\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "print(\"\u26a0\ufe0f Your keys are kept only in this running environment. Do NOT commit them to Git.\")\n",
        "\n",
        "# Required\n",
        "IBM_CLOUD_API_KEY = getpass.getpass(\"IBM Cloud API key: \")\n",
        "IBM_CLOUD_PROJECT_ID = input(\"IBM Cloud project_id: \").strip()\n",
        "\n",
        "# Region URL \u2013 change if you use a different region (for example: eu-de, ca-tor, etc.)\n",
        "default_url = \"https://us-south.ml.cloud.ibm.com\"\n",
        "entered_url = input(f\"IBM Cloud URL [{default_url}]: \").strip()\n",
        "IBM_CLOUD_URL = entered_url or default_url\n",
        "\n",
        "# Store them in environment variables (same pattern as your simple watsonx project)\n",
        "os.environ[\"IBM_CLOUD_API_KEY\"] = IBM_CLOUD_API_KEY\n",
        "os.environ[\"IBM_CLOUD_PROJECT_ID\"] = IBM_CLOUD_PROJECT_ID\n",
        "os.environ[\"IBM_CLOUD_URL\"] = IBM_CLOUD_URL\n",
        "\n",
        "# Also set aliases in case other code expects them\n",
        "os.environ[\"WATSONX_APIKEY\"] = IBM_CLOUD_API_KEY\n",
        "os.environ[\"PROJECT_ID\"] = IBM_CLOUD_PROJECT_ID\n",
        "os.environ[\"WATSONX_URL\"] = IBM_CLOUD_URL\n",
        "\n",
        "print(\"\\n\u2705 Credentials stored in environment variables.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3\ufe0f\u20e3 watsonx.ai quickstart with `ibm_watsonx_ai`\n",
        "\n",
        "This section mirrors the quickstart logic from your original project:\n",
        "\n",
        "- reads credentials from environment variables,\n",
        "- creates a watsonx.ai `ModelInference` client,\n",
        "- and generates text from a chosen foundation model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "watsonx-quickstart"
      },
      "source": [
        "import os\n",
        "from ibm_watsonx_ai import Credentials, APIClient\n",
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
        "\n",
        "# Read credentials from environment variables (set in the previous cell)\n",
        "api_key = os.environ.get(\"IBM_CLOUD_API_KEY\") or os.environ.get(\"WATSONX_APIKEY\")\n",
        "url = os.environ.get(\"IBM_CLOUD_URL\") or os.environ.get(\"WATSONX_URL\")\n",
        "project_id = os.environ.get(\"IBM_CLOUD_PROJECT_ID\") or os.environ.get(\"PROJECT_ID\")\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"Missing API key (IBM_CLOUD_API_KEY or WATSONX_APIKEY).\")\n",
        "if not url:\n",
        "    raise ValueError(\"Missing URL (IBM_CLOUD_URL or WATSONX_URL).\")\n",
        "if not project_id:\n",
        "    raise ValueError(\"Missing project id (IBM_CLOUD_PROJECT_ID or PROJECT_ID).\")\n",
        "\n",
        "print(\"\u2705 Credentials loaded.\")\n",
        "print(f\"URL: {url}\")\n",
        "print(f\"Project ID: {project_id}\")\n",
        "\n",
        "# Create client & model\n",
        "credentials = Credentials(url=url, api_key=api_key)\n",
        "client = APIClient(credentials=credentials, project_id=project_id)  # created for completeness / reuse\n",
        "\n",
        "# \ud83d\udc49 Choose a model that is available in your watsonx project/space.\n",
        "# Replace with whatever you actually have access to, for example:\n",
        "#   - \"ibm/granite-13b-chat-v2\"\n",
        "#   - \"ibm/granite-8b-code-instruct\"\n",
        "#   - \"meta-llama/llama-3-3-70b-instruct\"\n",
        "model_id = \"meta-llama/llama-3-3-70b-instruct\"  # Change if needed\n",
        "\n",
        "prompt = \"Write a short story about a robot who wants to be a painter.\"\n",
        "\n",
        "params = {\n",
        "    GenParams.DECODING_METHOD: \"greedy\",\n",
        "    GenParams.MAX_NEW_TOKENS: 200,\n",
        "}\n",
        "\n",
        "model = ModelInference(model_id=model_id, credentials=credentials, project_id=project_id)\n",
        "\n",
        "print(\"\\n\ud83d\ude80 Sending request to watsonx.ai...\")\n",
        "response = model.generate_text(prompt=prompt, params=params)\n",
        "print(\"\\n--- watsonx.ai Response ---\\n\")\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4\ufe0f\u20e3 Optional: Use watsonx.ai via LangChain\n",
        "\n",
        "This section shows how to call watsonx.ai through **LangChain** using\n",
        "`langchain_ibm.WatsonxLLM`. You can then build chains, tools, and\n",
        "agents on top of this LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "langchain-watsonx"
      },
      "source": [
        "from dotenv import load_dotenv\n",
        "from langchain_ibm import WatsonxLLM\n",
        "\n",
        "# If you prefer using a .env file, you can create it inside the Binder\n",
        "# environment (using Jupyter's file editor) and this call will load it.\n",
        "# NOTE: Do NOT commit a .env with real keys to a public repo.\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.environ.get(\"IBM_CLOUD_API_KEY\") or os.environ.get(\"WATSONX_APIKEY\")\n",
        "url = os.environ.get(\"IBM_CLOUD_URL\") or os.environ.get(\"WATSONX_URL\")\n",
        "project_id = os.environ.get(\"IBM_CLOUD_PROJECT_ID\") or os.environ.get(\"PROJECT_ID\")\n",
        "\n",
        "if not api_key or not url or not project_id:\n",
        "    raise ValueError(\"Missing credentials for LangChain example.\")\n",
        "\n",
        "# Reuse the same model_id as above or adjust as needed\n",
        "model_id = \"meta-llama/llama-3-3-70b-instruct\"  # Change if needed\n",
        "\n",
        "params = {\n",
        "    \"decoding_method\": \"greedy\",\n",
        "    \"max_new_tokens\": 128,\n",
        "}\n",
        "\n",
        "llm = WatsonxLLM(\n",
        "    model_id=model_id,\n",
        "    url=url,\n",
        "    apikey=api_key,\n",
        "    project_id=project_id,\n",
        "    params=params,\n",
        ")\n",
        "\n",
        "print(\"\ud83d\ude80 Calling watsonx.ai through LangChain...\")\n",
        "response = llm.invoke(\"Give me 3 concise study tips for learning Python.\")\n",
        "print(\"\\n--- LangChain + watsonx.ai Response ---\\n\")\n",
        "print(response)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}