{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3.1 â€“ Agent with Watsonx.ai (Google Colab Version)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Run this notebook in Google Colab\n",
    "\n",
    "**Prerequisites:**\n",
    "- IBM Cloud API Key ([Create one here](https://cloud.ibm.com/iam/apikeys))\n",
    "- Watsonx Project ID ([Find it in your watsonx.ai project](https://dataplatform.cloud.ibm.com/docs/content/wsj/getting-started/wml-plans.html?context=wx&audience=wdp))\n",
    "\n",
    "This notebook demonstrates building an **AI Agent** that can:\n",
    "- Use multiple tools (RAG service, calculator)\n",
    "- Plan which tool to use based on user input\n",
    "- Generate natural language responses\n",
    "\n",
    "**High-level flow:**\n",
    "1. User asks a question\n",
    "2. Granite model acts as a **planner** (chooses which tool to use)\n",
    "3. Python executes the selected tool\n",
    "4. Granite generates a **final answer** based on tool output\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required dependencies\n",
    "!pip install -qU \"ibm-watsonx-ai>=1.1.22\"\n",
    "!pip install -qU requests\n",
    "!pip install -qU pydantic\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Configure Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "import operator as op\n",
    "import getpass\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Prompt for Watsonx credentials\n",
    "WATSONX_APIKEY = getpass.getpass(\"Enter IBM Cloud API Key: \")\n",
    "WATSONX_PROJECT_ID = getpass.getpass(\"Enter Watsonx Project ID: \")\n",
    "WATSONX_URL = \"https://us-south.ml.cloud.ibm.com\"\n",
    "LLM_MODEL_ID = \"ibm/granite-3-3-8b-instruct\"  # You can change this to other Granite models\n",
    "\n",
    "print(\"\\nâœ… Credentials configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Watsonx Model\n",
    "\n",
    "We'll use the Granite model as our planner and answer generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import Model\n",
    "from ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watsonx_ai.foundation_models.utils.enums import DecodingMethods\n",
    "\n",
    "creds = Credentials(url=WATSONX_URL, api_key=WATSONX_APIKEY)\n",
    "\n",
    "params = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MAX_NEW_TOKENS: 512,\n",
    "    GenParams.MIN_NEW_TOKENS: 1,\n",
    "    GenParams.TEMPERATURE: 0.2,\n",
    "}\n",
    "\n",
    "planner_model = Model(\n",
    "    model_id=LLM_MODEL_ID,\n",
    "    credentials=creds,\n",
    "    project_id=WATSONX_PROJECT_ID,\n",
    "    params=params,\n",
    ")\n",
    "\n",
    "print(\"âœ… Watsonx Granite model initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Tools\n",
    "\n",
    "Our agent will have access to two tools:\n",
    "\n",
    "1. **RAG Service Tool** - Mock implementation (you can connect to a real RAG API)\n",
    "2. **Calculator Tool** - Safely evaluates arithmetic expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Service Tool (Mock)\n",
    "\n",
    "âš ï¸ **Note:** In the original notebook, this connects to a FastAPI `/ask` endpoint. For Colab, we'll use a mock implementation. You can replace this with a real API call if you have a deployed RAG service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def rag_service_tool(question: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Mock RAG service. Replace with actual API call if you have a deployed RAG endpoint.\n",
    "    \n",
    "    Example:\n",
    "        ACCELERATOR_API_URL = \"http://your-rag-api.com/ask\"\n",
    "        payload = {\"question\": question}\n",
    "        resp = requests.post(ACCELERATOR_API_URL, json=payload, timeout=60)\n",
    "        resp.raise_for_status()\n",
    "        return resp.json()\n",
    "    \"\"\"\n",
    "    # Mock response for demonstration\n",
    "    mock_responses = {\n",
    "        \"what is rag\": {\n",
    "            \"answer\": \"RAG (Retrieval Augmented Generation) is a technique that combines information retrieval with language model generation. It retrieves relevant documents from a knowledge base and uses them to generate more accurate and contextual responses.\",\n",
    "            \"citations\": [\"RAG Documentation\"],\n",
    "            \"model_id\": \"mock-model\",\n",
    "            \"latency_ms\": 150\n",
    "        },\n",
    "        \"default\": {\n",
    "            \"answer\": \"I don't have specific information about that in my knowledge base. This is a mock RAG response. In a real implementation, this would query your RAG API endpoint.\",\n",
    "            \"citations\": [],\n",
    "            \"model_id\": \"mock-model\",\n",
    "            \"latency_ms\": 100\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Simple keyword matching for demo\n",
    "    question_lower = question.lower()\n",
    "    if \"rag\" in question_lower:\n",
    "        return mock_responses[\"what is rag\"]\n",
    "    else:\n",
    "        return mock_responses[\"default\"]\n",
    "\n",
    "print(\"âœ… RAG service tool defined (using mock implementation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculator Tool\n",
    "\n",
    "Safe arithmetic calculator using AST parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe calculator implementation using AST\n",
    "_allowed_operators = {\n",
    "    ast.Add: op.add,\n",
    "    ast.Sub: op.sub,\n",
    "    ast.Mult: op.mul,\n",
    "    ast.Div: op.truediv,\n",
    "    ast.Pow: op.pow,\n",
    "    ast.Mod: op.mod,\n",
    "}\n",
    "\n",
    "def _eval_ast(node):\n",
    "    if isinstance(node, ast.Num):  # type: ignore[attr-defined]\n",
    "        return node.n\n",
    "    if isinstance(node, ast.BinOp) and type(node.op) in _allowed_operators:\n",
    "        return _allowed_operators[type(node.op)](_eval_ast(node.left), _eval_ast(node.right))\n",
    "    if isinstance(node, ast.UnaryOp) and isinstance(node.op, (ast.UAdd, ast.USub)):\n",
    "        value = _eval_ast(node.operand)\n",
    "        return +value if isinstance(node.op, ast.UAdd) else -value\n",
    "    raise ValueError(\"Unsupported expression\")\n",
    "\n",
    "def calculator_tool(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Safely evaluate a simple arithmetic expression.\n",
    "    Supports +, -, *, /, %, and exponentiation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed = ast.parse(expression, mode=\"eval\")\n",
    "        result = _eval_ast(parsed.body)\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "print(\"âœ… Calculator tool defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Define Planner Schema\n",
    "\n",
    "The planner decides which tool to use based on the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class ToolPlan(BaseModel):\n",
    "    tool: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "PLANNER_SYSTEM_PROMPT = (\n",
    "    \"You are a planner agent. You must choose exactly ONE tool per request.\\n\\n\"\n",
    "    \"Available tools:\\n\"\n",
    "    \"- rag_service: Use this to answer enterprise questions using the RAG API.\\n\"\n",
    "    \"- calculator: Use this to evaluate arithmetic expressions like '2 * (3 + 4)'.\\n\\n\"\n",
    "    \"Return a JSON object with keys 'tool' and 'arguments'. Do not include any extra text.\\n\"\n",
    "    \"If the user is clearly asking a math question, prefer 'calculator'. Otherwise, prefer 'rag_service'.\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Planner schema defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Implement Planner Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_tool_call(user_input: str) -> ToolPlan:\n",
    "    \"\"\"Ask the LLM which tool to use and with what arguments.\"\"\"\n",
    "    user_prompt = (\n",
    "        f\"User input: {user_input}\\n\\n\"\n",
    "        \"Respond ONLY with JSON, for example:\\n\"\n",
    "        '{\"tool\": \"calculator\", \"arguments\": {\"expression\": \"2 + 2\"}}'\n",
    "    )\n",
    "    prompt = f\"{PLANNER_SYSTEM_PROMPT}\\n\\n{user_prompt}\"\n",
    "    \n",
    "    raw = planner_model.generate_text(prompt=prompt)\n",
    "    text = raw.strip()\n",
    "    \n",
    "    # Try to extract JSON\n",
    "    try:\n",
    "        plan_dict = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # Fallback: try to find JSON substring\n",
    "        start = text.find(\"{\")\n",
    "        end = text.rfind(\"}\") + 1\n",
    "        if start >= 0 and end > start:\n",
    "            plan_dict = json.loads(text[start:end])\n",
    "        else:\n",
    "            raise ValueError(f\"Could not parse JSON from planner output: {text!r}\")\n",
    "    \n",
    "    return ToolPlan(**plan_dict)\n",
    "\n",
    "print(\"âœ… Planner function implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Implement Final Answer Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_ANSWER_SYSTEM = (\n",
    "    \"You are a helpful assistant. You will be given: the original user question, the tool you used, \"\n",
    "    \"and the tool output. Compose a clear and concise final answer. \"\n",
    "    \"If the tool output indicates an error, explain the error and suggest what the user can try.\"\n",
    ")\n",
    "\n",
    "def generate_final_answer(user_input: str, tool_name: str, tool_output: Any) -> str:\n",
    "    \"\"\"Call the LLM to turn tool output into a final answer.\"\"\"\n",
    "    context = (\n",
    "        f\"User question: {user_input}\\n\"\n",
    "        f\"Tool used: {tool_name}\\n\"\n",
    "        f\"Tool output: {tool_output}\\n\"\n",
    "        \"\\nPlease write the final answer for the user.\"\n",
    "    )\n",
    "    prompt = f\"{FINAL_ANSWER_SYSTEM}\\n\\n{context}\"\n",
    "    \n",
    "    raw = planner_model.generate_text(prompt=prompt)\n",
    "    return raw.strip()\n",
    "\n",
    "print(\"âœ… Final answer generator implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Orchestrate the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_once(user_input: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run one turn of the agent:\n",
    "    1. Plan which tool to use\n",
    "    2. Execute the tool\n",
    "    3. Generate final answer\n",
    "    \"\"\"\n",
    "    # Step 1: Plan\n",
    "    print(f\"\\nðŸ¤” Planning for: {user_input}\")\n",
    "    plan = plan_tool_call(user_input)\n",
    "    tool_name = plan.tool\n",
    "    args = plan.arguments or {}\n",
    "    \n",
    "    print(f\"ðŸ”§ Selected tool: {tool_name}\")\n",
    "    print(f\"ðŸ“‹ Arguments: {args}\")\n",
    "    \n",
    "    # Step 2: Execute tool\n",
    "    if tool_name == \"rag_service\":\n",
    "        question = args.get(\"question\") or user_input\n",
    "        tool_output = rag_service_tool(question)\n",
    "    elif tool_name == \"calculator\":\n",
    "        expr = args.get(\"expression\") or user_input\n",
    "        tool_output = calculator_tool(expr)\n",
    "    else:\n",
    "        tool_output = f\"Unknown tool: {tool_name}\"\n",
    "    \n",
    "    print(f\"âš™ï¸  Tool output: {tool_output}\")\n",
    "    \n",
    "    # Step 3: Generate final answer\n",
    "    print(\"\\nâœï¸  Generating final answer...\")\n",
    "    final_answer = generate_final_answer(user_input, tool_name, tool_output)\n",
    "    \n",
    "    return {\n",
    "        \"question\": user_input,\n",
    "        \"tool\": tool_name,\n",
    "        \"tool_args\": args,\n",
    "        \"tool_output\": tool_output,\n",
    "        \"final_answer\": final_answer,\n",
    "    }\n",
    "\n",
    "print(\"âœ… Agent orchestration implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test the Agent\n",
    "\n",
    "Let's test with a few different types of questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: RAG Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_1 = \"What is RAG and why do we use it?\"\n",
    "result_1 = run_agent_once(question_1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Question: {result_1['question']}\")\n",
    "print(f\"Tool used: {result_1['tool']}\")\n",
    "print(f\"\\nFinal Answer:\\n{result_1['final_answer']}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Math Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_2 = \"What is 2 * (3 + 4)?\"\n",
    "result_2 = run_agent_once(question_2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Question: {result_2['question']}\")\n",
    "print(f\"Tool used: {result_2['tool']}\")\n",
    "print(f\"\\nFinal Answer:\\n{result_2['final_answer']}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Another Math Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_3 = \"Calculate 15 * 8 + 42\"\n",
    "result_3 = run_agent_once(question_3)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Question: {result_3['question']}\")\n",
    "print(f\"Tool used: {result_3['tool']}\")\n",
    "print(f\"\\nFinal Answer:\\n{result_3['final_answer']}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Try Your Own Questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_question = input(\"Enter your question: \")\n",
    "result = run_agent_once(your_question)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RESULT\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Question: {result['question']}\")\n",
    "print(f\"Tool used: {result['tool']}\")\n",
    "print(f\"Tool arguments: {result['tool_args']}\")\n",
    "print(f\"\\nFinal Answer:\\n{result['final_answer']}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "You successfully completed this notebook! You learned how to:\n",
    "\n",
    "âœ… Build an AI agent using Watsonx Granite models  \n",
    "âœ… Implement tool selection via LLM planning  \n",
    "âœ… Create custom tools (RAG service, calculator)  \n",
    "âœ… Orchestrate multi-step agent workflows  \n",
    "âœ… Generate natural language responses from tool outputs  \n",
    "\n",
    "**Next Steps:**\n",
    "- Add more tools (web search, database query, etc.)\n",
    "- Connect the RAG service to a real API endpoint\n",
    "- Implement multi-turn conversations\n",
    "- Add error handling and retries\n",
    "- Experiment with different Granite models\n",
    "\n",
    "**Connecting to a Real RAG API:**\n",
    "\n",
    "To connect to a real RAG endpoint, modify the `rag_service_tool` function:\n",
    "\n",
    "```python\n",
    "def rag_service_tool(question: str) -> Dict[str, Any]:\n",
    "    ACCELERATOR_API_URL = \"http://your-rag-api.com/ask\"\n",
    "    payload = {\"question\": question}\n",
    "    start = time.time()\n",
    "    resp = requests.post(ACCELERATOR_API_URL, json=payload, timeout=60)\n",
    "    latency_ms = int((time.time() - start) * 1000)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "    data.setdefault(\"latency_ms\", latency_ms)\n",
    "    return data\n",
    "```\n",
    "\n",
    "For more information:\n",
    "- [Watsonx.ai Documentation](https://ibm.github.io/watsonx-ai-python-sdk/samples.html)\n",
    "- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)\n",
    "\n",
    "---\n",
    "\n",
    "**Copyright Â© 2024 IBM. This notebook and its source code are released under the terms of the MIT License.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
