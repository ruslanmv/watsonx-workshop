{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# PoC #6: Content Moderation System üõ°Ô∏è\n\n## Business Use Case\nAutomatically detect and flag inappropriate content in user-generated text (comments, reviews, posts).\n\n## Production Applications\n- Social media platforms\n- Review websites\n- Community forums\n- Chat applications\n\n---"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install -qU \"ibm-watsonx-ai>=1.1.22\"\nprint(\"‚úÖ Ready\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import getpass\nfrom ibm_watsonx_ai import Credentials\nfrom ibm_watsonx_ai.foundation_models import Model\nfrom ibm_watsonx_ai.metanames import GenTextParamsMetaNames as GenParams\n\nmodel = Model(\n    model_id=\"ibm/granite-3-8b-instruct\",\n    credentials=Credentials(url=\"https://us-south.ml.cloud.ibm.com\", api_key=getpass.getpass(\"API Key: \")),\n    project_id=getpass.getpass(\"Project ID: \"),\n    params={GenParams.MAX_NEW_TOKENS: 50, GenParams.TEMPERATURE: 0.1}\n)\nprint(\"‚úÖ Moderator initialized\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def moderate_content(text: str) -> dict:\n    prompt = f\"\"\"Analyze this user-generated content for inappropriate material.\n\nRespond with ONE word: SAFE, TOXIC, SPAM, or INAPPROPRIATE\n\nContent: {text}\n\nClassification:\"\"\"\n    \n    result = model.generate_text(prompt=prompt).strip().upper()\n    \n    action_map = {\n        \"SAFE\": \"‚úÖ APPROVED\",\n        \"TOXIC\": \"üö´ BLOCKED\",\n        \"SPAM\": \"‚ö†Ô∏è FILTERED\",\n        \"INAPPROPRIATE\": \"üö´ BLOCKED\"\n    }\n    \n    return {\n        \"text\": text,\n        \"classification\": result if result in action_map else \"SAFE\",\n        \"action\": action_map.get(result, \"‚úÖ APPROVED\")\n    }"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Test content samples\ntest_content = [\n    \"This product is amazing! Highly recommend to everyone.\",\n    \"This is garbage and you're all idiots for buying it.\",\n    \"Click here for FREE MONEY!!! Act now!!!\",\n    \"The quality could be better, but overall it's decent.\",\n    \"I hate this company and everything they stand for!\"\n]\n\nprint(\"üõ°Ô∏è CONTENT MODERATION RESULTS\\n\" + \"=\"*80)\n\nfor content in test_content:\n    result = moderate_content(content)\n    print(f\"\\n{result['action']:15} | {content[:60]}...\" if len(content) > 60 else f\"\\n{result['action']:15} | {content}\")"]},
  {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Interactive test\nuser_content = input(\"Enter content to moderate: \")\nresult = moderate_content(user_content)\n\nprint(f\"\\n{'='*80}\")\nprint(f\"Content: {result['text']}\")\nprint(f\"Classification: {result['classification']}\")\nprint(f\"Action: {result['action']}\")\nprint(f\"{'='*80}\")"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["---\n\n## Production Benefits\n- üõ°Ô∏è Protect brand reputation\n- ‚ö° Real-time moderation\n- üìä Reduce manual review by 80%\n- üåç Scalable to millions of posts\n\n### Next Steps\n1. Add multi-language support\n2. Implement appeal workflow\n3. Train on custom categories\n4. Add confidence scoring\n\n---"]}
 ],
 "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}},
 "nbformat": 4,
 "nbformat_minor": 4
}
